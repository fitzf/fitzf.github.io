<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[基于Docker的CI/CD流水线实践]]></title>
    <url>%2F2017%2F07%2F07%2F%E5%9F%BA%E4%BA%8EDocker%E7%9A%84CI-CD%E6%B5%81%E6%B0%B4%E7%BA%BF%E5%AE%9E%E8%B7%B5%2F</url>
    <content type="text"><![CDATA[概要随着DevOps理念不断的传播，大部分IT从业者对于DevOps本身也有了一定的了解和认识，然而企业内部想根据DevOps思想实践，这并不是一件很简单的事情。一方面由于企业内部的历史环境以及组织结构问题，另外一方面因为业界并没有一套标准的开源工具集可以借鉴（关于几家基于Docker创业的服务提供商暂时除外）。 那么该篇内容主要讲解如何借助开源工具结合CI/CD的场景，将Docker融入到部署单元中去，进行持续集成、测试到最终的持续部署，开发人员最终只需要去关注业务的访问入口就可以知道业务是否正常，并可以通过一系列的监控工具去及时发现业务异常。 在整个DevOps部署流水线中需要以下几个部分：CI部分、CD部分、服务调度(治理)部分、监控部分、日志部分。本篇文章将通过一个简单的go-web应用去进行基于Docker的CI/CD流水线的测试。 基于Docker的CI/CD的优势一个完整的流程入上图所示，用户（也就是开发人员）将包含Dockerfile的源码从本地push到Git服务器上，然后触发Jenkins进行构建源码，源码构建完成后紧接着进行Docker image的构建，一切构建完成之后，顺带将构建成功的image上传到企业内部的镜像仓库，到此刻为止，其实一个基本的CI（持续集成）已经算是结束，剩下的部分就是持续部署或者进行持续的交付开发产物了。在以前传统的软件发布模式中，持续集成的产物是编译打包好的代码，如果想要发布程序，发布系统需要在持续集成的制品库中去获得对应的代码，然后根据一系列的环境检查来准备应用的运行时环境，而在此过程中往往会涉及到比较多的基本组件依赖，所以在整体的发布周期内来看，还是有一些问题的。在Docker或者容器时代，我们将容器的镜像构建部分融入到持续集成（CI）环节，最终持续集成的产出物是一些已经处理好依赖关系，基本不需要人工进行二次干预的Docker image，而在CD环节，发布系统只需要设置和管理很少的信息就能够很快将image运行起来，快速地将业务发布出去。 在上面整个环节中，其实无非就是增加了Docker的那一层处理，但其实在整个软件开发的生命周期中，它是产生了极大的影响的。首先，部署系统不需要为统一的部署框架去做更多逻辑抽象，业务研发在开发代码的过程中选择自己依赖的base image即可，最终运行起来的业务也就是你当时提供的base image的模样；其次，由于base image已经处理好了相关的依赖，所以当发布系统拿到业务的image的时候，发布操作将会变得异常迅速，这对于互联网时代可谓是非常重要的；最后一点，也是我感受最深的，就是研发构建好的image可以在任何的Docker环境中run起来，研发人员不需要再关系环境一致性的问题，他们在自己本地的测试环境能够运行起来的应用，那么到生成环境也一定可以。 为什么第三点我感触比较深呢？因为以前经常有研发兄弟跑过来跟我们讲，我们代码在本地运行一切顺利，代码给你们上到生产就各种问题。所以如果在整个流程中使用Docker image来讲所有的环境固化，从此mm就再也不用担心和研发兄弟扯皮环境不一致的问题啦。 基于Docker的CI/CD的开源方案实现一、自助式Git管理工具Gogs的部署安装Gogs部署 Gogs部署在10.0.0.1主机上，映射到宿主机端口为32770 1$ docker run -itd -p 32770:3000 -v /export/CI-CD/mygit:/data --name jdjr-gogs gogs:17-04-25 MySQL建库授权 MySQL部署在10.0.0.2上，映射到宿主机端口为32771 1$ docker run -itd -p 32771:3306 --name jdjr-mysql pandora-mysql 配置Gogs 上面两步没有问题之后就可以直接访问:ip:32770 （也就是Gogs暴露的端口）进行相关的配置。 配置数据库相关： 配置Git地址： 配置完成后进行初始化，并创建管理员用户后就可正常使用。 如图，现在正在使用的本地Git。 现在就可以将源码托管在本地的Gogs仓库上了。 二、Jenkins持续集成工具部署安装Jenkins部署 Jenkins在官方的image基础上增加了go 1.7的编译环境，部署在10.0.0.2上，映射到宿主机端口32791。 1$ docker run -itd -p 32791:8080 -p 32790:50000 -v /export/jenkins/:/var/jenkine_home/ --name jdjr-jenkins jdjr-jenkins 注意：需要将Jenkins相关数据以及编译环境映射到Docker宿主机上，因为后期编译完成后Jenkins容器需要docker build构建业务image。 Jenkins容器运行起来之后，就可以直接访问10.0.0.2:32791进行初始化安装配置了。 在Web上面访问Jenkins地址进行初始化配置，需要写入ID进行解锁Jenkins（Web上会提示在哪个路径下存放，直接使用docker logs也可查看）；解锁后就是正常的安装相关的Plugins了，只要网络没有问题，一般都正常通过。 Jenkine安装成功后界面如下： 创建Jenkins项目，并配置构建脚本（也可通过相应的Plugins进行配置）。 创建一个新的名为test的项目，配置相关的源码管理以及构建条件以及相关的后续操作。 配置Jenkins环境 注意：由上图可以看出来，Jenkins进行构建image和持续部署测试的过程都是通过SSH到远端去执行的，因此需要再Jenkins容器中生成SSH公私钥对，并和Jenkins的宿主机以及持续部署测试的宿主机进行免密认证。虽然Jenkins本身其实支持了很多种Plugin来支持管理Docker的，比如说Docker build step plugin、Docker Build Publish Plugin，但是由于过多的Plugin会造成实际环境中的维护成本大大增加，因此我们选择简单粗暴的脚本方式，上图中的Execute shell只是简单的示例。 1$ docker exec -it myjenkins bash 生成公私钥对之后，将公钥传给要远程部署的机器就OK了，目的是要让Jenkins容器能够免密登录远程服务器，并能执行sudo命令。 三、通过配置Nginx反向代理来访问Git，Jenkins以及测试实例反向代理Nginx部署在10.0.0.4:80上。 配置Nginx 注意：centos6.8-jdjr-test-app:v2镜像默认是包含Nginx以及配置管理工具的。 1$ docker run -itd --name biaoge-nginx centos6.8-jdjr-test-app:v2 注意：此时Git上的源码还没有编译部署，我只是暂时定义了一个端10.0.0.3:32768，等完成整个CI/CD流程后直接访问web.biao.com就可以看到源码部署的效果。 测试访问 在本地绑定如下hosts 10.0.0.4 jenkins.biao.com 访问mygit.biao.com上面的源码： 访问jenkins.biao.com上的构建任务： 注意：test项目在之前我们已经配置好了，所以可以直接触发构建部署。手动触发构建部署： 注意：在构建过程这里可以看到详细的构建过程，构建成功后便可以访问我们的goweb服务了。访问web.biao.com服务： 持续集成持续部署的效果 更新源码中的部分内容，进行重新构建访问。 修改web的源码在Jenkins上进行再次构建： 再次访问web.biao.com服务： 对比前后两个Web，发现不仅欢迎语由“biaoge”变成了“逼格运维说”，而且第二行的字符串由4e7853008397变为0ce402beclle，也就是是之前的那个Container已经被销毁，我们现在访问的web.biao.com是重新编译后运行在新的container里面的实例。]]></content>
      <categories>
        <category>Collection</category>
      </categories>
      <tags>
        <tag>DevOps</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[快速切换hosts文件的开源程序SwitchHosts]]></title>
    <url>%2F2017%2F07%2F07%2F%E5%BF%AB%E9%80%9F%E5%88%87%E6%8D%A2hosts%E6%96%87%E4%BB%B6%E7%9A%84%E5%BC%80%E6%BA%90%E7%A8%8B%E5%BA%8FSwitchHosts%2F</url>
    <content type="text"><![CDATA[SwitchHosts 是一款用于快速切换 hosts 文件的开源小程序，基于 MIT 协议开源。拥有Windows版, Linux版和Mac OS 版。基于 Electron 开发，同时使用了 React、Ant Design 以及 CodeMirror 等框架/库。需要 Node.js 环境。 功能特性包括： 快速切换 hosts hosts 文件语法高亮 在线/本地 hosts 方案选择 系统托盘图标快速切换 Host文件编辑时，点击行号快速切换注释 macOS: 支持 Alfred workflow 快速切换 Website https://oldj.github.io/SwitchHostsGithub https://github.com/oldj/SwitchHosts]]></content>
      <categories>
        <category>Collection</category>
        <category>Softwore</category>
      </categories>
      <tags>
        <tag>Hosts</tag>
        <tag>Softwore</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker Swarm 入门]]></title>
    <url>%2F2017%2F07%2F06%2FDocker-Swarm-%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[Swarm 在 Docker 1.12 版本之前属于一个独立的项目，在 Docker 1.12 版本发布之后，该项目合并到了 Docker 中，成为 Docker 的一个子命令。目前，Swarm 是 Docker 社区提供的唯一一个原生支持 Docker 集群管理的工具。它可以把多个 Docker 主机组成的系统转换为单一的虚拟 Docker 主机，使得容器可以组成跨主机的子网网络。 Swarm 认识Swarm 是目前 Docker 官方唯一指定（绑定）的集群管理工具。Docker 1.12 内嵌了 swarm mode 集群管理模式。 为了方便演示跨主机网络，我们需要用到一个工具——Docker Machine，这个工具与 Docker Compose、Docker Swarm 并称 Docker 三剑客，下面我们来看看如何安装 Docker Machine： 123$ curl -L https://github.com/docker/machine/releases/download/v0.9.0-rc2/docker-machine-`uname -s`-`uname -m` &gt;/tmp/docker-machine &amp;&amp; chmod +x /tmp/docker-machine &amp;&amp; sudo cp /tmp/docker-machine /usr/local/bin/docker-machine 安装过程和 Docker Compose 非常类似。现在 Docker 三剑客已经全部到齐了。在开始之前，我们需要了解一些基本概念，有关集群的 Docker 命令如下： docker swarm：集群管理，子命令有 init, join,join-token, leave, update docker node：节点管理，子命令有 demote, inspect,ls, promote, rm, ps, update docker service：服务管理，子命令有 create, inspect, ps, ls ,rm , scale, update docker stack/deploy：试验特性，用于多应用部署，等正式版加进来再说。 创建集群首先使用 Docker Machine 创建一个虚拟机作为 manger 节点。 1234567891011121314151617181920212223$ docker-machine create --driver virtualbox manager1 Running pre-create checks...(manager1) Unable to get the latest Boot2Docker ISO release version: Get https://api.github.com/repos/boot2docker/boot2docker/releases/latest: dial tcp: lookup api.github.com on [::1]:53: server misbehavingCreating machine...(manager1) Unable to get the latest Boot2Docker ISO release version: Get https://api.github.com/repos/boot2docker/boot2docker/releases/latest: dial tcp: lookup api.github.com on [::1]:53: server misbehaving(manager1) Copying /home/zuolan/.docker/machine/cache/boot2docker.iso to /home/zuolan/.docker/machine/machines/manager1/boot2docker.iso...(manager1) Creating VirtualBox VM...(manager1) Creating SSH key...(manager1) Starting the VM...(manager1) Check network to re-create if needed...(manager1) Found a new host-only adapter: "vboxnet0"(manager1) Waiting for an IP...Waiting for machine to be running, this may take a few minutes...Detecting operating system of created instance...Waiting for SSH to be available...Detecting the provisioner...Provisioning with boot2docker...Copying certs to the local machine directory...Copying certs to the remote machine...Setting Docker configuration on the remote daemon...Checking connection to Docker...Docker is up and running!To see how to connect your Docker Client to the Docker Engine running on this virtual machine, run: docker-machine env manager1 查看虚拟机的环境变量等信息，包括虚拟机的 IP 地址： 1234567$ docker-machine env manager1export DOCKER_TLS_VERIFY="1"export DOCKER_HOST="tcp://192.168.99.100:2376"export DOCKER_CERT_PATH="/home/zuolan/.docker/machine/machines/manager1"export DOCKER_MACHINE_NAME="manager1"# Run this command to configure your shell: # eval $(docker-machine env manager1) 然后再创建一个节点作为 work 节点。 1$ docker-machine create --driver virtualbox worker1 现在我们有了两个虚拟主机，使用 Machine 的命令可以查看： 1234$ docker-machine ls NAME ACTIVE DRIVER STATE URL SWARM DOCKER ERRORSmanager1 - virtualbox Running tcp://192.168.99.100:2376 v1.12.3 worker1 - virtualbox Running tcp://192.168.99.101:2376 v1.12.3 但是目前这两台虚拟主机并没有什么联系，为了把它们联系起来，我们需要 Swarm 登场了。因为我们使用的是 Docker Machine 创建的虚拟机，因此可以使用 docker-machine ssh 命令来操作虚拟机，在实际生产环境中，并不需要像下面那样操作，只需要执行 docker swarm 即可。 把 manager1 加入集群： 12345678910$ docker-machine ssh manager1 docker swarm init --listen-addr 192.168.99.100:2377 --advertise-addr 192.168.99.100Swarm initialized: current node (23lkbq7uovqsg550qfzup59t6) is now a manager.To add a worker to this swarm, run the following command: docker swarm join \ --token SWMTKN-1-3z5rzoey0u6onkvvm58f7vgkser5d7z8sfshlu7s4oz2gztlvj-c036gwrakjejql06klrfc585r \ 192.168.99.100:2377To add a manager to this swarm, run 'docker swarm join-token manager' and follow the instructions. 用 –listen-addr 指定监听的 ip 与端口，实际的 Swarm 命令格式如下，本例使用 Docker Machine 来连接虚拟机而已： 1$ docker swarm init --listen-addr &lt;MANAGER-IP&gt;:&lt;PORT&gt; 接下来，再把 work1 加入集群中： 1234$ docker-machine ssh worker1 docker swarm join --token \ SWMTKN-1-3z5rzoey0u6onkvvm58f7vgkser5d7z8sfshlu7s4oz2gztlvj-c036gwrakjejql06klrfc585r \ 192.168.99.100:2377This node joined a swarm as a worker. 上面 join 命令中可以添加 –listen-addr $WORKER1_IP:2377 作为监听准备，因为有时候可能会遇到把一个 work 节点提升为 manger 节点的可能，当然本例子没有这个打算就不添加这个参数了。 注意：如果你在新建集群时遇到双网卡情况，可以指定使用哪个 IP，例如上面的例子会有可能遇到下面的错误。 123$ docker-machine ssh manager1 docker swarm init --listen-addr $MANAGER1_IP:2377Error response from daemon: could not choose an IP address to advertise since this system has multiple addresses on different interfaces (10.0.2.15 on eth0 and 192.168.99.100 on eth1) - specify one with --advertise-addrexit status 1 发生错误的原因是因为有两个 IP 地址，而 Swarm 不知道用户想使用哪个，因此要指定 IP。 12345678910$ docker-machine ssh manager1 docker swarm init --advertise-addr 192.168.99.100 --listen-addr 192.168.99.100:2377 Swarm initialized: current node (ahvwxicunjd0z8g0eeosjztjx) is now a manager.To add a worker to this swarm, run the following command: docker swarm join \ --token SWMTKN-1-3z5rzoey0u6onkvvm58f7vgkser5d7z8sfshlu7s4oz2gztlvj-c036gwrakjejql06klrfc585r \ 192.168.99.100:2377To add a manager to this swarm, run 'docker swarm join-token manager' and follow the instructions. 集群初始化成功。 现在我们新建了一个有两个节点的“集群”，现在进入其中一个管理节点使用 docker node 命令来查看节点信息： 1234$ docker-machine ssh manager1 docker node lsID HOSTNAME STATUS AVAILABILITY MANAGER STATUS23lkbq7uovqsg550qfzup59t6 * manager1 Ready Active Leaderdqb3fim8zvcob8sycri3hy98a worker1 Ready Active 现在每个节点都归属于 Swarm，并都处在了待机状态。Manager1 是领导者，work1 是工人。 现在，我们继续新建虚拟机 manger2、worker2、worker3，现在已经有五个虚拟机了，使用 docker-machine ls 来查看虚拟机： 123456NAME ACTIVE DRIVER STATE URL SWARM DOCKER ERRORSmanager1 - virtualbox Running tcp://192.168.99.100:2376 v1.12.3 manager2 - virtualbox Running tcp://192.168.99.105:2376 v1.12.3 worker1 - virtualbox Running tcp://192.168.99.102:2376 v1.12.3 worker2 - virtualbox Running tcp://192.168.99.103:2376 v1.12.3 worker3 - virtualbox Running tcp://192.168.99.104:2376 v1.12.3 然后我们把剩余的虚拟机也加到集群中。 添加 worker2 到集群中： 1234$ docker-machine ssh worker2 docker swarm join \ --token SWMTKN-1-3z5rzoey0u6onkvvm58f7vgkser5d7z8sfshlu7s4oz2gztlvj-c036gwrakjejql06klrfc585r \ 192.168.99.100:2377This node joined a swarm as a worker. 添加 worker3 到集群中： 1234$ docker-machine ssh worker3 docker swarm join \ --token SWMTKN-1-3z5rzoey0u6onkvvm58f7vgkser5d7z8sfshlu7s4oz2gztlvj-c036gwrakjejql06klrfc585r \ 192.168.99.100:2377This node joined a swarm as a worker. 添加 manager2 到集群中：先从 manager1 中获取 manager 的 token： 123456$ docker-machine ssh manager1 docker swarm join-token managerTo add a manager to this swarm, run the following command: docker swarm join \ --token SWMTKN-1-3z5rzoey0u6onkvvm58f7vgkser5d7z8sfshlu7s4oz2gztlvj-8tn855hkjdb6usrblo9iu700o \192.168.99.100:2377 然后添加 manager2 到集群中： 1234$ docker-machine ssh manager2 docker swarm join \ --token SWMTKN-1-3z5rzoey0u6onkvvm58f7vgkser5d7z8sfshlu7s4oz2gztlvj-8tn855hkjdb6usrblo9iu700o \ 192.168.99.100:2377This node joined a swarm as a manager. 现在再来查看集群信息： 1234567$ docker-machine ssh manager2 docker node lsID HOSTNAME STATUS AVAILABILITY MANAGER STATUS16w80jnqy2k30yez4wbbaz1l8 worker1 Ready Active 2gkwhzakejj72n5xoxruet71z worker2 Ready Active 35kutfyn1ratch55fn7j3fs4x worker3 Ready Active a9r21g5iq1u6h31myprfwl8ln * manager2 Ready Active Reachabledpo7snxbz2a0dxvx6mf19p35z manager1 Ready Active Leader 建立跨主机网络为了演示更清晰，下面我们把宿主机也加入到集群之中，这样我们使用 Docker 命令操作会清晰很多。直接在本地执行加入集群命令： 1234$ docker swarm join \ --token SWMTKN-1-3z5rzoey0u6onkvvm58f7vgkser5d7z8sfshlu7s4oz2gztlvj-8tn855hkjdb6usrblo9iu700o \ 192.168.99.100:2377This node joined a swarm as a manager. 现在我们有三台 manager，三台 worker。其中一台是宿主机，五台虚拟机。 12345678$ docker node lsID HOSTNAME STATUS AVAILABILITY MANAGER STATUS6z2rpk1t4xucffzlr2rpqb8u3 worker3 Ready Active 7qbr0xd747qena4awx8bx101s * user-pc Ready Active Reachable9v93sav79jqrg0c7051rcxxev manager2 Ready Active Reachablea1ner3zxj3ubsiw4l3p28wrkj worker1 Ready Active a5w7h8j83i11qqi4vlu948mad worker2 Ready Active d4h7vuekklpd6189fcudpfy18 manager1 Ready Active Leader 查看网络状态： 123456$ docker network lsNETWORK ID NAME DRIVER SCOPE764ff31881e5 bridge bridge local fbd9a977aa03 host host local 6p6xlousvsy2 ingress overlay swarm e81af24d643d none null local 可以看到在 swarm 上默认已有一个名为 ingress 的 overlay 网络, 默认在 swarm 里使用，本例子中会创建一个新的 overlay 网络。 123456789$ docker network create --driver overlay swarm_test4dm8cy9y5delvs5vd0ghdd89s$ docker network lsNETWORK ID NAME DRIVER SCOPE764ff31881e5 bridge bridge localfbd9a977aa03 host host local6p6xlousvsy2 ingress overlay swarme81af24d643d none null local4dm8cy9y5del swarm_test overlay swarm 这样一个跨主机网络就搭建好了，但是现在这个网络只是处于待机状态，下一小节我们会在这个网络上部署应用。 在跨主机网络上部署应用首先我们上面创建的节点都是没有镜像的，因此我们要逐一 pull 镜像到节点中，这里我们使用前面搭建的私有仓库。 1234567891011121314151617181920212223242526272829303132333435$ docker-machine ssh manager1 docker pull reg.example.com/library/nginx:alpine alpine: Pulling from library/nginxe110a4a17941: Pulling fs layer... ...7648f5d87006: Pull completeDigest: sha256:65063cb82bf508fd5a731318e795b2abbfb0c22222f02ff5c6b30df7f23292feStatus: Downloaded newer image for reg.example.com/library/nginx:alpine$ docker-machine ssh manager2 docker pull reg.example.com/library/nginx:alpinealpine: Pulling from library/nginxe110a4a17941: Pulling fs layer... ...7648f5d87006: Pull completeDigest: sha256:65063cb82bf508fd5a731318e795b2abbfb0c22222f02ff5c6b30df7f23292feStatus: Downloaded newer image for reg.example.com/library/nginx:alpine$ docker-machine ssh worker1 docker pull reg.example.com/library/nginx:alpine alpine: Pulling from library/nginxe110a4a17941: Pulling fs layer... ...7648f5d87006: Pull completeDigest: sha256:65063cb82bf508fd5a731318e795b2abbfb0c22222f02ff5c6b30df7f23292feStatus: Downloaded newer image for reg.example.com/library/nginx:alpine$ docker-machine ssh worker2 docker pull reg.example.com/library/nginx:alpinealpine: Pulling from library/nginxe110a4a17941: Pulling fs layer... ...7648f5d87006: Pull completeDigest: sha256:65063cb82bf508fd5a731318e795b2abbfb0c22222f02ff5c6b30df7f23292feStatus: Downloaded newer image for reg.example.com/library/nginx:alpine$ docker-machine ssh worker3 docker pull reg.example.com/library/nginx:alpinealpine: Pulling from library/nginxe110a4a17941: Pulling fs layer... ...7648f5d87006: Pull completeDigest: sha256:65063cb82bf508fd5a731318e795b2abbfb0c22222f02ff5c6b30df7f23292feStatus: Downloaded newer image for reg.example.com/library/nginx:alpine 上面使用 docker pull 分别在五个虚拟机节点拉取 nginx:alpine 镜像。接下来我们要在五个节点部署一组 Nginx 服务。 部署的服务使用 swarm_test 跨主机网络。 12$ docker service create --replicas 2 --name helloworld --network=swarm_test nginx:alpine5gz0h2s5agh2d2libvzq6bhgs 查看服务状态： 123$ docker service lsID NAME REPLICAS IMAGE COMMAND5gz0h2s5agh2 helloworld 0/2 nginx:alpine 查看 helloworld 服务详情（为了方便阅读，已调整输出内容）： 1234$ docker service ps helloworldID NAME IMAGE NODE DESIRED STATE CURRENT STATE ERRORay081uome3 helloworld.1 nginx:alpine manager1 Running Preparing 2 seconds ago 16cvore0c96 helloworld.2 nginx:alpine worker2 Running Preparing 2 seconds ago 可以看到两个实例分别运行在两个节点上。 进入两个节点，查看服务状态（为了方便阅读，已调整输出内容）： 123456$ docker-machine ssh manager1 docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES119f787622c2 nginx:alpine "nginx -g ..." 4 minutes ago Up 4 minutes 80/tcp, 443/tcp hello ...$ docker-machine ssh worker2 docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES5db707401a06 nginx:alpine "nginx -g ..." 4 minutes ago Up 4 minutes 80/tcp, 443/tcp hello ... 上面输出做了调整，实际的 NAMES 值为： 12helloworld.1.ay081uome3eejeg4mspa8pdlxhelloworld.2.16cvore0c96rby1vp0sny3mvt 记住上面这两个实例的名称。现在我们来看这两个跨主机的容器是否能互通：首先使用 Machine 进入 manager1 节点，然后使用 docker exec -i 命令进入 helloworld.1 容器中 ping 运行在 worker2 节点的 helloworld.2 容器。 12345678$ docker-machine ssh manager1 docker exec -i helloworld.1.ay081uome3eejeg4mspa8pdlx \ ping helloworld.2.16cvore0c96rby1vp0sny3mvtPING helloworld.2.16cvore0c96rby1vp0sny3mvt (10.0.0.4): 56 data bytes64 bytes from 10.0.0.4: seq=0 ttl=64 time=0.591 ms64 bytes from 10.0.0.4: seq=1 ttl=64 time=0.594 ms64 bytes from 10.0.0.4: seq=2 ttl=64 time=0.624 ms64 bytes from 10.0.0.4: seq=3 ttl=64 time=0.612 ms^C 然后使用 Machine 进入 worker2 节点，然后使用 docker exec -i 命令进入 helloworld.2 容器中 ping 运行在 manager1 节点的 helloworld.1 容器。 12345678$ docker-machine ssh worker2 docker exec -i helloworld.2.16cvore0c96rby1vp0sny3mvt \ ping helloworld.1.ay081uome3eejeg4mspa8pdlx PING helloworld.1.ay081uome3eejeg4mspa8pdlx (10.0.0.3): 56 data bytes64 bytes from 10.0.0.3: seq=0 ttl=64 time=0.466 ms64 bytes from 10.0.0.3: seq=1 ttl=64 time=0.465 ms64 bytes from 10.0.0.3: seq=2 ttl=64 time=0.548 ms64 bytes from 10.0.0.3: seq=3 ttl=64 time=0.689 ms^C 可以看到这两个跨主机的服务集群里面各个容器是可以互相连接的。 为了体现 Swarm 集群的优势，我们可以使用虚拟机的 ping 命令来测试对方虚拟机内的容器。 1234567891011121314$ docker-machine ssh worker2 ping helloworld.1.ay081uome3eejeg4mspa8pdlxPING helloworld.1.ay081uome3eejeg4mspa8pdlx (221.179.46.190): 56 data bytes64 bytes from 221.179.46.190: seq=0 ttl=63 time=48.651 ms64 bytes from 221.179.46.190: seq=1 ttl=63 time=63.239 ms64 bytes from 221.179.46.190: seq=2 ttl=63 time=47.686 ms64 bytes from 221.179.46.190: seq=3 ttl=63 time=61.232 ms^C$ docker-machine ssh manager1 ping helloworld.2.16cvore0c96rby1vp0sny3mvtPING helloworld.2.16cvore0c96rby1vp0sny3mvt (221.179.46.194): 56 data bytes64 bytes from 221.179.46.194: seq=0 ttl=63 time=30.150 ms64 bytes from 221.179.46.194: seq=1 ttl=63 time=54.455 ms64 bytes from 221.179.46.194: seq=2 ttl=63 time=73.862 ms64 bytes from 221.179.46.194: seq=3 ttl=63 time=53.171 ms^C 上面我们使用了虚拟机内部的 ping 去测试容器的延迟，可以看到延迟明显比集群内部的 ping 值要高。 Swarm 集群负载现在我们已经学会了 Swarm 集群的部署方法，现在来搭建一个可访问的 Nginx 集群吧。体验最新版的 Swarm 所提供的自动服务发现与集群负载功能。首先删掉上一节我们启动的 helloworld 服务： 12$ docker service rm helloworld helloworld 然后在新建一个服务，提供端口映射参数，使得外界可以访问这些 Nginx 服务： 12$ docker service create --replicas 2 --name helloworld -p 7080:80 --network=swarm_test nginx:alpine9gfziifbii7a6zdqt56kocyun 查看服务运行状态： 123$ docker service ls ID NAME REPLICAS IMAGE COMMAND9gfziifbii7a helloworld 2/2 nginx:alpine 不知你有没有发现，虽然我们使用 –replicas 参数的值都是一样的，但是上一节中获取服务状态时，REPLICAS 返回的是 0/2，现在的 REPLICAS 返回的是 2/2。同样使用 docker service ps 查看服务详细状态时（下面输出已经手动调整为更易读的格式），可以看到实例的 CURRENT STATE 中是 Running 状态的，而上一节中的 CURRENT STATE 中全部是处于 Preparing 状态。 1234$ docker service ps helloworldID NAME IMAGE NODE DESIRED STATE CURRENT STATE ERROR9ikr3agyi... helloworld.1 nginx:alpine user-pc Running Running 13 seconds ago 7acmhj0u... helloworld.2 nginx:alpine worker2 Running Running 6 seconds ago 这就涉及到 Swarm 内置的发现机制了，目前 Docker 1.12 中 Swarm 已经内置了服务发现工具，我们不再需要像以前使用 Etcd 或者 Consul 这些工具来配置服务发现。对于一个容器来说如果没有外部通信但又是运行中的状态会被服务发现工具认为是 Preparing 状态，本小节例子中因为映射了端口，因此有了 Running 状态。现在我们来看 Swarm 另一个有趣的功能，当我们杀死其中一个节点时，会发生什么。首先 kill 掉 worker2 的实例： 12$ docker-machine ssh worker2 docker kill helloworld.2.7acmhj0udzusv1d7lu2tbuhu4helloworld.2.7acmhj0udzusv1d7lu2tbuhu4 稍等几秒，再来看服务状态： 12345678$ docker service ps helloworldID NAME IMAGE NODE DESIRED STATE CURRENT STATE ERROR9ikr3agyi... helloworld.1 nginx:alpine zuolan-pc Running Running 19 minutes ago 8f866igpl... helloworld.2 nginx:alpine manager1 Running Running 4 seconds ago 7acmhj0u... \_ helloworld.2 nginx:alpine worker2 Shutdown Failed 11 seconds ago ...exit...$ docker service ls ID NAME REPLICAS IMAGE COMMAND9gfziifbii7a helloworld 2/2 nginx:alpine 可以看到即使我们 kill 掉其中一个实例，Swarm 也会迅速把停止的容器撤下来，同时在节点中启动一个新的实例顶上来。这样服务依旧还是两个实例在运行。此时如果你想添加更多实例可以使用 scale 命令： 12$ docker service scale helloworld=3helloworld scaled to 3 查看服务详情，可以看到有三个实例启动了： 1234$ docker service ps helloworldID NAME IMAGE NODE DESIRED STATE CURRENT STATE ERROR9ikr3agyi... helloworld.1 nginx:alpine user-pc Running Running 30 minutes ago 8f866igpl... helloworld.2 nginx:alpine manager1 Running Running 11 minutes ago 7acmhj0u... \_ helloworld.2 nginx:alpine worker2 Shutdown Failed 11 minutes ago exit1371vexr1jm... helloworld.3 nginx:alpine worker2 Running Running 4 seconds ago 现在如果想减少实例数量，一样可以使用 scale 命令： 12$ docker service scale helloworld=2helloworld scaled to 2 至此，Swarm的主要用法都已经介绍完了，主要讲述了 Swarm 集群网络的创建与部署。介绍了 Swarm 的常规应用，包括 Swarm 的服务发现、负载均衡等，然后使用 Swarm 来配置跨主机容器网络，并在上面部署应用。 转自： http://www.jianshu.com/p/9eb9995884a5]]></content>
      <categories>
        <category>Collection</category>
      </categories>
      <tags>
        <tag>Docker</tag>
        <tag>Docker Swarm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MyCLI：一个支持自动补全和语法高亮的MySQL客户端]]></title>
    <url>%2F2017%2F06%2F07%2FMyCLI%EF%BC%9A%E4%B8%80%E4%B8%AA%E6%94%AF%E6%8C%81%E8%87%AA%E5%8A%A8%E8%A1%A5%E5%85%A8%E5%92%8C%E8%AF%AD%E6%B3%95%E9%AB%98%E4%BA%AE%E7%9A%84MySQL%E5%AE%A2%E6%88%B7%E7%AB%AF%2F</url>
    <content type="text"><![CDATA[MyCLI 是一个易于使用的命令行客户端，可用于受欢迎的数据库管理系统 MySQL、MariaDB 和 Percona，支持自动补全和语法高亮。它是使用 prompt_toolkit 库写的，需要 Python 2.7、3.3、3.4、3.5 和 3.6 的支持。MyCLI 还支持通过 SSL 安全连接到 MySQL 服务器。 MyCLI 的特性 当你第一次使用它的时候，将会自动创建一个文件 ~/.myclirc。 当输入 SQL 的关键词和数据库中的表、视图和列时，支持自动补全。 默认情况下也支持智能补全，能根据上下文的相关性提供补全建议。 比如： 12SELECT * FROM &lt;Tab&gt; - 这将显示出数据库中的表名。SELECT * FROM users WHERE &lt;Tab&gt; - 这将简单的显示出列名称。 通过使用 Pygents 支持语法高亮 支持 SSL 连接 提供多行查询支持 它可以将每一个查询和输出记录到一个文件中（默认情况下禁用）。 允许保存收藏一个查询（使用 \fs 别名 保存一个查询，并可使用 \f 别名 运行它）。 支持 SQL 语句执行和表查询计时 以更吸引人的方式打印表格数据 如何在 Linux 上为 MySQL 和 MariaDB 安装 MyCLI在 Debian/Ubuntu 发行版上，你可以很容易的像下面这样使用 apt 命令 来安装 MyCLI 包： 12$ sudo apt-get update$ sudo apt-get install mycli 同样，在 Fedora 22+ 上也有 MyCLI 的可用包，你可以像下面这样使用 dnf 命令 来安装它： 1$ sudo dnf install mycli 对于其他 Linux 发行版，比如 RHEL/CentOS，你需要使用 Python 的 pip 工具来安装 MyCLI。首先，使用下面的命令来安装 pip： 1$ sudo yum install pip 安装好 pip 以后，你可以像下面这样安装 MyCLI： 1$ sudo pip install mycli 在 Linux 中如何使用 MyCLI 连接 MySQL 和 MariaDB安装好 MyCLI 以后，你可以像下面这样使用它： 1$ mycli -u root -h localhost 自动补全对于关键词和 SQL 函数可以进行简单的自动补全： 智能补全当输入 FROM 关键词以后会进行表名称的补全： 别名支持当表的名称设置别名以后，也支持列名称的补全： 语法高亮支持 MySQL 语法高亮： 格式化 SQL 的输出MySQL 的输出会通过 less 命令[1] 进行格式化输出： 要登录 MySQL 并同时选择数据库，你可以使用和下面类似的命令： 123$ mycli local_database$ mycli -h localhost -u root app_db$ mycli mysql://amjith@localhost:3306/django_poll 更多使用选项，请输入： 1$ mycli --help MyCLI 主页： http://mycli.net/index]]></content>
      <categories>
        <category>Collection</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
        <tag>Shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[你应该知道的5个Docker实用工具]]></title>
    <url>%2F2017%2F05%2F27%2F%E4%BD%A0%E5%BA%94%E8%AF%A5%E7%9F%A5%E9%81%93%E7%9A%845%E4%B8%AADocker%E5%AE%9E%E7%94%A8%E5%B7%A5%E5%85%B7%2F</url>
    <content type="text"><![CDATA[【摘要】网上有很多不错的Docker工具，大部分在github上都是开源的。最近两年，我一直在使用Docker，并将其应用到了一些开发项目上。如果你刚开始使用Docker，你会发现它能应用到的实例远远多于预想。Docker能为你做更多，不会让你失望的！ Docker社区非常活跃，每天都有许多新的实用工具出现。因此，天天去检查更新，试图跟上社区的步伐确实有点困难。所以我在此分享在工作中收集到的一些有趣而实用的Docker工具，帮助大家提高日常工作效率。 下面开始一一介绍我在使用Docker的过程中找到的有用工具吧。 watchtower：自动更新Docker容器watchtower监视容器运行过程，并且能够捕捉到容器中的变化。当watchtower检测到有镜像发生变化，会自动使用新镜像重启容器。我在本地开发环境中创建的最后一个镜像就用到了watchtower。 watchtower本身就像一个Docker镜像，所以它启动容器的方式和别的镜像无异。运行watchtower的命令如下： 上面的代码中，我们用到了一个安装文件/var/run/docker.sock。这个文件主要用来使watchtower与Docker后台API交互。 interval30秒的选项主要用来定义watchtower的轮询间隔时间。watchtower还支持一些别的选项，具体可以查看他们的文档。 现在，开启一个容器，用watchtower来监控。 watchtower会开始监控friendlyhello容器。接下来我把新镜像push到Docker Hub，watchtower接下来就会检测到有新镜像可用。它会关掉容器，然后用新镜像重启容器。这里会用到我们刚刚传到运行命令中的选项，换句话说，容器会在4000:80 公共端口选项上开启。 默认情况下，watchtower会轮询Dockder Hub注册表查找更新的镜像。你也可以通过在环境变量REPO_USER和REPO_PASS中添加指定注册表证书，来设置watchtower轮询私有注册表。 了解更多watchtower的用法，我推荐watchtower文档。 docker-gc：收集垃圾容器和镜像docker-gc工具能够帮助Docker host清理不需要的容器和镜像。它可以删除存在一小时以上的容器。同时，它也可以删除没有容器的镜像。 docker-gc可以被当做脚本，也可以被视为容器。我们用容器方法运行docker-gc，用它来查找可以被删除的容器和镜像。 在上述命令中，我们安装Docker socket文件，这样docker-gc就可以和Docker API进行交互。设置环境变量DRY_RUN=1，查找可被删除的容器和镜像。如果我们不这样设置，docker-gc直接删除它们。所以在删除之前，还是先确认一下。以上代码的输出结果如下： 确认需要删除的容器和镜像之后，再次运行docker-gc来进行删除清理，这次就不用再设置DRY_RUN参数了。 上述命令运行后的输出会告诉你哪些容器和镜像已经被docker-gc删除。 了解更多docker-gc支持的选项，我推荐阅读docker-gc documentation。 docker-slim：给你的容器瘦身如果你对Docker镜像的大小有过担忧，docker-slim绝对是一丸灵丹妙药。 docker-slim工具可以通过静态和动态分析，针对你的“胖镜像”创建对应的“瘦镜像”。在Github上下载二进制文件，即可使用docker-slim。该二进制文件在Linux和Mac可用。下载之后添加到路径PATH。 我创建了一个Docker镜像示例应用“friendlyhello”，Docker官方文档中有用到。这个镜像的大小如下图所示，194MB。 这么简单的一个应用，我们就要下载194MB的数据。再来看看docker-slim究竟能让它“瘦”多少。 docker-slim工具先是对“胖镜像”进行一系列的检测，最终创建了对应的“瘦镜像”。看一下“瘦镜像”的大小： 正如上图所示，“瘦镜像”大小为24.9MB。开启容器，运行照旧。docker-slim对java、python、ruby、和Node.js应用都非常友好。 你自己也试一下吧，看看结果如何。以我个人的项目来说，我认为docker-slim在大部分情况下都能适用。阅读docker-slim文档了解更多。 rocker：打破Dockerfile限制很多Docker用户都用Dockerfile来构建镜像。Dockerfile是定义命令的声明方式，通过在命令行调用这些命令，可以对镜像进行操作。 rocker给Dockerfile的指令集增加了新的指令。rocker是由Grammaryly创建的，原意是用来解决Dockerfile格式的问题。Grammaryly团队写过一篇博客解释当初的动机。我建议你也看一下这篇博客，可以更好的理解rocker。他们在博客中提出的两个关键问题是： Docker镜像的大小构建速度缓慢博客还提到了rocker添加的一些新指令。查看rocker文档了解更多。 MOUNT用来分享volume，这样依赖管理工具就可以重用。FROM指令在Dockerfile中也存在。rocker添加了不止一条FROM指令。这就意味着，一个Rockerfile可以通过创建多个镜像。首个指令集使用所有依赖来创建artifact，第二个指令集可以使用已有的artifact。这种做法极大的降低了镜像的大小。TAG用来标记处于不同构建阶段的镜像。这样一来就不在需要手动标记镜像了。PUSH用来把镜像push到registry。ATTACH用来和中间步骤交互，在debug的时候非常有用。安装rocker，对Mac用户来说，只要运行几条brew命令就行了： 安装完成后，就可以使用rocker创建镜像。 创建镜像并将其push到Docker Hub，可以用下面这条命令： rocker功能十分完备，了解更多，请参阅其文档。 ctop：容器的顶层界面工具ctop是我最近才开始使用的工具，它可以为多个容器提供实时显示的数据视图。如果你是Mac用户，可以按下面的命令安装ctop。 安装之后，只需配置DOCKER_HOST环境变量，即可使用ctop。 运行ctop命令，可以查看所有容器的状态。 运行 ctop-a命令，可以仅查看当前运行的容器。 ctop简单好用，查看机器上运行的容器非常方便。了解更多，请看ctop文档。]]></content>
      <categories>
        <category>Collection</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker的Secrets管理]]></title>
    <url>%2F2017%2F05%2F18%2FDocker%E7%9A%84Secrets%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[我相信当我们意识到重要且敏感的访问信息已经暴露到公共网络上，并可能使您的微服务无条件被访问。随着我们依赖于的开发出来的服务化的量不断增加， 这时跟踪敏感细节的数量也有所增加。为了应对这个问题，在“secrets managemen”领域出现了工具。 在这篇文章中，我们将看Docker Secrets，要求在Docker 1.13及更高版本的新秘密管理功能。 从Docker的角度来看，该功能不需要太多的工作，但是您可能需要重构应用程序以利用它。我们将介绍如何做到这一点的想法，但不是详细的。 Docker的 Secrets只适用于Docker群集，主要是因为这是秘密管理最有意义的领域。毕竟，Swarm是针对多个Docker实例需要在他们之间共享访问细节的生产用途。如果要在独立容器中使用秘密管理，则需要运行 scale值设置为1 的容器。适用于Mac和Windows的Docker不支持多节点群集模式，但您可以使用它们使用Docker Machine创建多节点群集。 创建两个机器，然后创建一个两个节点，并从该组中的一个swarm环境中运行本文中的案例。 获得Secrets当您从命令行创建Secrets时，您可以使用所有可用的工具来创建随机密码和管道输出。例如，为数据库用户创建一个随机密码： opensslrand-base6420|dockersecretcreatemariadb_password- 这将返回一个秘密的ID。 您需要再次发出此命令以生成MariaDB root用户的密码。您将需要这样才能开始使用，但您不需要为每项服务。 opensslrand-base6420|dockersecretcreatemariadb_root_password- 如果你已经忘记了你创建的秘密， 可以用ls查看，也可以用以下命令查看docker secret ls 替换secrets为了保持秘密，良好的秘密，服务之间的通信发生在您定义的覆盖网络中。它们只能通过调用其ID来在该覆盖网络中使用。 dockernetworkcreate-doverlaymariadb_private 这也将返回该网络的ID。再次，你可以docker network ls查看相关网络 创建服务这个例子将有一个Docker节点运行MariaDB，一个运行Python的节点。在最终的应用程序中，Python应用程序将读取和写入数据库。 首先，添加一个MariaDB服务。此服务使用您创建的网络进行通信，之前创建的秘密保存为两个文件：一个用于根密码，一个用于默认用户密码。然后将所需的所有变量作为环境变量传递给服务。 dockerservicecreate\ –namemariadb\ –replicas1\ –networkmariadb_private\ –mounttype=volume,source=mydata,destination=/var/lib/mariadb\ –secretsource=mariadb_root_password,target=mariadb_root_password\ –secretsource=mariadb_password,target=mariadb_password\ -eMARIADB_ROOT_PASSWORD_FILE=”/run/secrets/mariadb_root_password”\ -eMARIADB_PASSWORD_FILE=”/run/secrets/mariadb_password”\ -eMARIADB_USER=”python”\ -eMARIADB_DATABASE=”python”\ Python实例再次使用您创建的专用网络，并复制网络中可访问的秘密。一个更好的（生产就绪的）选项将是创建您的应用程序在管理程序中需要的数据库，而不会给应用程序访问根密码，但这仅仅是一个例子。 dockerservicecreate\ –namecspython\ –replicas1\ –networkmariadb_private\ –publish50000:5000\ –mounttype=volume,source=pydata,destination=/var/www/html\ –secretsource=mariadb_root_password,target=python_root_password,mode=0400\ –secretsource=mariadb_password,target=python_password,mode=0400\ -ePYTHON_DB_USER=”python”\ -ePYTHON_DB_ROOT_PASSWORD_FILE=”/run/secrets/python_root_password”\ -ePYTHON_DB_PASSWORD_FILE=”/run/secrets/python_password”\ -ePYTHON_DB_HOST=”mariadb:3306”\ -ePYTHON_DB_NAME=”python”\ 上面的示例使用我创建的一个简单的Docker映像，它设置用于使用Flask创建Web应用程序的软件包，用于提供Web页面和PyMySQL来进行数据库访问。代码没有做太多，但显示了如何从Docker容器访问环境变量。 例如，要连接到没有指定数据库的数据库服务器： importos importMySQLdb db=MySQLdb.connect(host=os.environ[‘PYTHON_DB_HOST’], user=os.environ[‘PYTHON_DB_ROOT_USER’], passwd=os.environ[‘PYTHON_DB_PASSWORD_FILE’]) cur=db.cursor() print(db) db.close() 更新secrets 频繁更改敏感信息是个好习惯。但是，您可能知道，在应用程序中更新这些细节是一个沉闷的过程，最不愿意避免。通过服务，Docker Secrets管理允许您更改值，而无需更改代码。 创建一个新秘密： opensslrand-base6420|dockersecretcreatemariadb_password_march- 从MariaDB服务中删除当前密码的访问权限： dockerserviceupdate\ –secret-rmmariadb_password\ 并让它访问新的秘密，将目标指向新的值： dockerserviceupdate\ –secret-addsource=mariadb_password_march,target=mysql_password\ 更新Python服务： dockerserviceupdate\ –secret-rmmariadb_password\ –secret-addsource=mariadb_password_march,target=python_password,mode=0400\ 并删除旧秘密： dockersecretrmmariadb_password 扩展说明Docker Secrets是一个新功能，但Docker鼓励镜像维护人员尽快为Docker用户提供更好的安全性。这需要允许与上述示例类似的过程，其中容器可以从通过生成秘密而不是硬编码到应用中创建的文件来读取其需要的每个参数。这可以强制实施集装箱应用程序，因为容器可以来回走动，但是始终可以访问您的应用程序运行所需的重要信息。]]></content>
      <categories>
        <category>Essay</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[四个Kubernetes集群管理工具]]></title>
    <url>%2F2017%2F05%2F18%2F%E5%9B%9B%E4%B8%AAKubernetes%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7%2F</url>
    <content type="text"><![CDATA[几乎所有用过Kubernetes的人都会发现其缺点，随着大K在负载平衡和工作管理方面的重大改进，用户可以将注意力逐渐转移到其他地方了，这里有四个项目可以减轻Kubernetes集群管理的负载。 Kube-applierKubernetes成功的关键是其与除Google以外的IT厂商和产品的接触。云存储公司Box收购了Kubernetes，并开放了一些用于帮助其内部部署的项目，kube-applier就是这样一个项目。 作为Kubernetes服务运行的Kube-applier，为Gube仓库中托管的Kubernetes集群提供了一组声明性配置文件，并将其持续应用于集群中的pod。无论何时对定义文件进行任何更改，它们都将被自动提取并应用于相关的pod。 更改也可以按计划或按需应用。Kube应用程序每次运行时都会记录其行为，并提供与Prometheus兼容的指标，以便用户及时了解影响集群的行为。 Kubetop有时最简单的工具反而是最有用的，比如Kubetop，它用Python编写，Kubetop会列出所有当前运行的节点，这些节点上所有的pod，这些pod中的所有容器，每个节点的CPU和内存利用率，类似于Unix/Linux top的命令。它不应该用来替代更精细的日志记录或报告工具，因为它产生的信息太简单了，但有时候简单会让阅读Kubernetes集群报告更节省时间。 如果您只需要快速了解哪些因素和命令行影响了集群，这是一个很方便的选项。Kubernetes的kubectl也有类似的功能，但是Kubetop的输出格式更加整齐。 Kubectx/K8senvKubernetes有一个“上下文”的概念，用于引用具有不同配置数据的离散集群。用kubectl命令行工具在上下文之间切换可能是冗长和笨拙的，所以第三方提出了在flash中切换上下文的方法。 一个简单的shell脚本，Kubectx可以为Kubernetes上下文分配短名称，并使用短名称在它们之间切换。将破折号（-）传递给kubectx，将被切换回以前的内容，而无需记住名称。该脚本还支持完成名称的选项卡，因此用户不必挖掘长名称并手动重新键入。 另外一个shell脚本K8senv要简单得多，但功能远远不够强大。例如，它不能在当前和最后一个上下文之间进行翻转。 kubeadm-dind-cluster如果你想启动一个本地的单节点Kubernetes实例进行测试，那么Kubernetes提供了一个很好的默认组件：Minikube。但是对于那些想要测试和开发多节点集群Kubernetes的人还有一个选择：Mirantis的kubeadm-dind-cluster（KDC）。 KDC通过使用Kubernetes的kubeadm应用程序来启动由Docker容器而不是VM组成的集群。这可以让您在使用Kubernetes时更快地重新启动集群，因此可以更快速地查看任何代码更改造成的影响，也可以在持续集成环境中使用KDC，而不会遇到嵌套虚拟化问题。KDC运行跨平台的Linux，MacOS，Windows，并且不需要Go安装，因为它使用了Dockerized构建的Kubernetes。]]></content>
      <categories>
        <category>Essay</category>
      </categories>
      <tags>
        <tag>Kubernetes</tag>
        <tag>k8s</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 9 中的 9 个新特性]]></title>
    <url>%2F2017%2F05%2F16%2FJava-9-%E4%B8%AD%E7%9A%84-9-%E4%B8%AA%E6%96%B0%E7%89%B9%E6%80%A7%2F</url>
    <content type="text"><![CDATA[Java 9 中的 9 个新特性 Java 8 发布三年多之后，即将快到2017年7月下一个版本发布的日期了。 你可能已经听说过 Java 9 的模块系统，但是这个新版本还有许多其它的更新。 这里有九个令人兴奋的新功能将与 Java 9 一起发布。 Java 平台级模块系统Java 9 的定义功能是一套全新的模块系统。当代码库越来越大，创建复杂，盘根错节的“意大利面条式代码”的几率呈指数级的增长。这时候就得面对两个基础的问题: 很难真正地对代码进行封装, 而系统并没有对不同部分（也就是 JAR 文件）之间的依赖关系有个明确的概念。每一个公共类都可以被类路径之下任何其它的公共类所访问到, 这样就会导致无意中使用了并不想被公开访问的 API。此外，类路径本身也存在问题: 你怎么知晓所有需要的 JAR 都已经有了, 或者是不是会有重复的项呢? 模块系统把这俩个问题都给解决了。 模块化的 JAR 文件都包含一个额外的模块描述器。在这个模块描述器中, 对其它模块的依赖是通过 “requires” 来表示的。另外, “exports” 语句控制着哪些包是可以被其它模块访问到的。所有不被导出的包默认都封装在模块的里面。如下是一个模块描述器的示例，存在于 “module-info.java” 文件中: module blog {我们可以如下展示模块： 请注意，两个模块都包含封装的包，因为它们没有被导出（使用橙色盾牌可视化）。 没有人会偶然地使用来自这些包中的类。Java 平台本身也使用自己的模块系统进行了模块化。通过封装 JDK 的内部类，平台更安全，持续改进也更容易。 当启动一个模块化应用时， JVM 会验证是否所有的模块都能使用，这基于 requires 语句——比脆弱的类路径迈进了一大步。模块允许你更好地强制结构化封装你的应用并明确依赖。你可以在这个课程中学习更多关于 Java 9 中模块工作的信息 。 Linking当你使用具有显式依赖关系的模块和模块化的 JDK 时，新的可能性出现了。你的应用程序模块现在将声明其对其他应用程序模块的依赖以及对其所使用的 JDK 模块的依赖。为什么不使用这些信息创建一个最小的运行时环境，其中只包含运行应用程序所需的那些模块呢？ 这可以通过 Java 9 中的新的 jlink 工具实现。你可以创建针对应用程序进行优化的最小运行时映像而不需要使用完全加载 JDK 安装版本。 JShell: 交互式 Java REPL许多语言已经具有交互式编程环境，Java 现在加入了这个俱乐部。您可以从控制台启动 jshell ，并直接启动输入和执行 Java 代码。 jshell 的即时反馈使它成为探索 API 和尝试语言特性的好工具。 测试一个 Java 正则表达式是一个很好的说明 jshell 如何使您的生活更轻松的例子。 交互式 shell 还可以提供良好的教学环境以及提高生产力，您可以在此了解更多信息。在教人们如何编写 Java 的过程中，不再需要解释 “public static void main（String [] args）” 这句废话。 改进的 Javadoc有时一些小事情可以带来很大的不同。你是否就像我一样在一直使用 Google 来查找正确的 Javadoc 页面呢？ 这不再需要了。Javadoc 现在支持在 API 文档中的进行搜索。另外，Javadoc 的输出现在符合兼容 HTML5 标准。此外，你会注意到，每个 Javadoc 页面都包含有关 JDK 模块类或接口来源的信息。 集合工厂方法通常，您希望在代码中创建一个集合（例如，List 或 Set ），并直接用一些元素填充它。 实例化集合，几个 “add” 调用，使得代码重复。 Java 9，添加了几种集合工厂方法： Set ints = Set.of(1, 2, 3);List strings = List.of(“first”, “second”);除了更短和更好阅读之外，这些方法也可以避免您选择特定的集合实现。 事实上，从工厂方法返回已放入数个元素的集合实现是高度优化的。这是可能的，因为它们是不可变的：在创建后，继续添加元素到这些集合会导致 “UnsupportedOperationException” 。 改进的 Stream API长期以来，Stream API 都是 Java 标准库最好的改进之一。通过这套 API 可以在集合上建立用于转换的申明管道。在 Java 9 中它会变得更好。Stream 接口中添加了 4 个新的方法：dropWhile, takeWhile, ofNullable。还有个 iterate 方法的新重载方法，可以让你提供一个 Predicate (判断条件)来指定什么时候结束迭代： IntStream.iterate(1, i -&gt; i &lt; 100, i -&gt; i + 1).forEach(System.out::println);第二个参数是一个 Lambda，它会在当前 IntStream 中的元素到达 100 的时候返回 true。因此这个简单的示例是向控制台打印 1 到 99。 除了对 Stream 本身的扩展，Optional 和 Stream 之间的结合也得到了改进。现在可以通过 Optional 的新方法 stram 将一个 Optional 对象转换为一个(可能是空的) Stream 对象： Stream s = Optional.of(1).stream();在组合复杂的 Stream 管道时，将 Optional 转换为 Stream 非常有用。 私有接口方法Java 8 为我们带来了接口的默认方法。 接口现在也可以包含行为，而不仅仅是方法签名。 但是，如果在接口上有几个默认方法，代码几乎相同，会发生什么情况？ 通常，您将重构这些方法，调用一个可复用的私有方法。 但默认方法不能是私有的。 将复用代码创建为一个默认方法不是一个解决方案，因为该辅助方法会成为公共API的一部分。 使用 Java 9，您可以向接口添加私有辅助方法来解决此问题： public interface MyInterface {如果您使用默认方法开发 API ，那么私有接口方法可能有助于构建其实现。 HTTP/2Java 9 中有新的方式来处理 HTTP 调用。这个迟到的特性用于代替老旧的 HttpURLConnection API，并提供对 WebSocket 和 HTTP/2 的支持。注意：新的 HttpClient API 在 Java 9 中以所谓的孵化器模块交付。也就是说，这套 API 不能保证 100% 完成。不过你可以在 Java 9 中开始使用这套 API： HttpClient client = HttpClient.newHttpClient();HttpRequest req =除了这个简单的请求/响应模型之外，HttpClient 还提供了新的 API 来处理 HTTP/2 的特性，比如流和服务端推送。 多版本兼容 JAR我们最后要来着重介绍的这个特性对于库的维护者而言是个特别好的消息。当一个新版本的 Java 出现的时候，你的库用户要花费数年时间才会切换到这个新的版本。这就意味着库得去向后兼容你想要支持的最老的 Java 版本 (许多情况下就是 Java 6 或者 7)。这实际上意味着未来的很长一段时间，你都不能在库中运用 Java 9 所提供的新特性。幸运的是，多版本兼容 JAR 功能能让你创建仅在特定版本的 Java 环境中运行库程序时选择使用的 class 版本： multirelease.jar在上述场景中， multirelease.jar 可以在 Java 9 中使用, 不过 Helper 这个类使用的不是顶层的multirelease.Helper 这个 class, 而是处在“META-INF/versions/9”下面的这个。这是特别为 Java 9 准备的 class 版本，可以运用 Java 9 所提供的特性和库。同时，在早期的 Java 诸版本中使用这个 JAR 也是能运行的，因为较老版本的 Java 只会看到顶层的这个 Helper 类。]]></content>
      <categories>
        <category>Essay</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java开源项目]]></title>
    <url>%2F2017%2F05%2F04%2Fjava%E5%BC%80%E6%BA%90%E9%A1%B9%E7%9B%AE%2F</url>
    <content type="text"><![CDATA[原文地址：http://blog.longjiazuo.com/archives/2625 开源相关的文章链接：Apache的开源软件列表 http://www.oschina.net/project/apache Java开源Apache项目 http://www.open-open.com/56.htm 阿里巴巴的开源软件列表 http://www.oschina.net/project/alibaba 百度的开源软件列表 http://www.oschina.net/project/baidu 腾讯的开源软件列表 http://www.oschina.net/project/tencent 华为的开源软件列表 http://www.oschina.net/project/huawei Netflix的开源软件列表 http://www.oschina.net/project/netflix 大公司都有哪些开源项目 http://www.cnblogs.com/dunitian/p/5581520.html 2017年你不能错过的Java类库 http://www.importnew.com/23858.html 公司开源导航页 https://www.oschina.net/company 开源项目链接地址：【spring项目】spring以及子项目: github地址:https://github.com/spring-projects 【spring cloud项目】spring cloud系列项目: github地址:https://github.com/spring-cloud 【apache基金会】apache开源项目列表: apache地址:http://www.apache.org/index.html#projects-list apache项目github地址: github地址:https://github.com/apache 【eclipse基金会】轻量级的高性能JVM应用平台Vert.x apache地址:https://github.com/eclipse/vert.x官方参考文档：http://vertx.io/docs/ 【阿里巴巴】开源JSON处理框架fastjson: github地址:https://github.com/alibaba/fastjson 开源数据库连接池druid： github地址:https://github.com/alibaba/druid 开源分布式服务框架dubbo： github地址:https://github.com/alibaba/dubbo 开源分布式开放消息队列RocketMQ： github地址:https://github.com/alibaba/RocketMQ备注：RocketMQ已经进入apache孵化器,在孵化器的github地址如下：github地址:https://github.com/apache/incubator-rocketmq 开源实时流式计算框架jstorm github地址:https://github.com/alibaba/jstorm 开源分布式数据库同步系统otter github地址:https://github.com/alibaba/otter 开源分布式数据库服务中间件cobar github地址:https://github.com/alibaba/cobar 【唯品会】开源调度框架Saturn: github地址:https://github.com/vipshop/Saturn 【当当】开源调度框架elastic-job: github地址:https://github.com/dangdangdotcom/elastic-job 开源分库分表中间件Sharding-JDBC: github地址:https://github.com/dangdangdotcom/sharding-jdbc 开源分布式服务框架dubbox: github地址:https://github.com/dangdangdotcom/dubbox 【百度】分布式系统配置管理disconf github地址:https://github.com/knightliao/disconf 【腾讯】开源基于微服务的平台Tars github地址:https://github.com/Tencent/Tars 【携程】开源Redis多数据中心复制管理系统x-pipe github地址:https://github.com/ctripcorp/x-pipe 开源配置管理平台apollo github地址:https://github.com/ctripcorp/apollo 开源数据库访问框架dal github地址:https://github.com/ctripcorp/dal 【大众点评】开源实时应用监控平台cat github地址:https://github.com/dianping/cat 【谷歌Google】开源java轻量级IOC框架Guice github地址:https://github.com/google/guice 开源基于java1.6的类库集合的扩展guava github地址:https://github.com/google/guava 【移动支付公司Square】开源处理网络请求的网络框架OkHttp github地址:https://github.com/square/okhttp 网络请求框架Retrofit github地址:https://github.com/square/retrofit 【mybatis项目】Sql映射持久层框架mybatis github地址:https://github.com/mybatis/mybatis-3 【hibernate项目】对象关系映射框架hibernate github地址:https://github.com/hibernate/hibernate-orm 开源组织或者个人项目说明：由于一些项目的名字比较类似,为了区分把作者加上,作者署名团队或者主要开发者。 spring boot中文参考文档作者：qibaoguang github地址:https://github.com/qibaoguang/Spring-Boot-Reference-Guide spring4中文参考文档作者：Way Lau github地址:https://github.com/waylau/spring-framework-4-reference 开源分布式数据库中间件Mycat-Server作者：mycat开源团队 github地址:https://github.com/MyCATApache/Mycat-Server 开源分布式数据库中间件mycat文档mycat-doc作者：mycat开源团队 github地址:https://github.com/MyCATApache/Mycat-doc 基于spring的基础框架库springside作者：江南白衣 github地址:https://github.com/springside/springside4 开源信息化快速开发平台jeesite作者：thinkgem github地址:https://github.com/thinkgem/jeesite Java资源大全中文版awesome-java-cn作者：伯乐在线 github地址:https://github.com/jobbole/awesome-java-cn 通用权限管理系统cl-privilege作者：pumadong github地址:https://github.com/pumadong/cl-privilege 开源分布式应用追踪分析系统sky-walking作者：sky-walking团队 github地址:https://github.com/wu-sheng/sky-walking 轻量级Java Web框架smart-framework作者：黄勇 git.oschina地址:http://git.oschina.net/huangyong/smart-framework 许雪里github:作者：许雪里 github地址:https://github.com/xuxueli 响应式函数编程框架RxJava作者：ReactiveX github地址:https://github.com/ReactiveX/RxJava 常用的java基础工具类iceroot作者：iceroot github地址:https://github.com/iceroot/iceroot 开源轻量级的,高性能的事件总线MBassador作者：Benjamin Diedrichsen github地址:https://github.com/bennidi/mbassador 通过注解来减少Java中的重复代码工具lombok作者：Reinier Zwitserloot github地址:https://github.com/rzwitserloot/lombok 简单日志门面slf4j作者：QOS.ch github地址:https://github.com/qos-ch/slf4j 模拟测试框架Mockito作者：mockito github地址:https://github.com/mockito/mockito 结合JUnit、 Guice、 Mockito的高效组合测试框架Jukito作者：Arcbees github地址:https://github.com/ArcBees/Jukito 轻量化的分布式服务框架rsf作者：Hasor Group 码云地址:http://git.oschina.net/zycgit/rs]]></content>
      <categories>
        <category>Collection</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[怎样在复杂代码中找bug？]]></title>
    <url>%2F2017%2F04%2F20%2F%E6%80%8E%E6%A0%B7%E5%9C%A8%E5%A4%8D%E6%9D%82%E4%BB%A3%E7%A0%81%E4%B8%AD%E6%89%BEbug%EF%BC%9F%2F</url>
    <content type="text"><![CDATA[避免错误1、缺少必要的注释大段的if-else缺少注释，让维护者无法快速分辨分支逻辑。特定地方存在hack或复杂逻辑的代码，缺少注释会让后来者不明所以。为了你好，也为了后来者好，请务必加上代码。说不准以后还是由你来维护这段代码。 2、不变和变化的部分拆分程序员中流传着一句话，此处不要写死，将来必改。有经验的程序员会将一些业务层的逻辑抽象出来，写成配置文件，好处就是若后续需求有改变，只需改配置文件即可，肯定不会引入bug。 3、忽视测试部分程序员中又流传着一句话，没有测试的代码等于没写。虽不敢全部赞同，却也有几分道理。从测试用例驱动开发，持续集成，每次编译自动跑测试用例，能够保证系统的稳定同时也减轻测试成本。自己改的的部分做好自测，理解需求，做一个有责任心的工程师。 4、直接操作数据你应该通过方法去操作数据，而不是直接操作数据,这样能够保证你总能操作数据正确。例如一个类中定义的属性发生变化了，代码中所有涉及到直接操作该属性的代码都需要修改。如果通过方法操作该属性，则仅需修改操作方法，对于外部调用者，类属性变化被屏蔽了，遵循了解耦的原则，代码稳定性大大提高。 5、缺乏文档或文档质量低下前期文档很重要，不论是框架的API使用手册，还是需求或设计文档，以及各种既定流程的规范，不同种类的模板及核对表，等等这些文档，对于项目来说都是非常重要的资源。而往往有些项目，这类文档就是交由非软件行业的人员来编写，或者前期根本不打算在文档上浪费时间。 6、无尽的需求变更，永远追不上的进度这是最常见也是最可怕的，因为无论怎样，我们都无法完成它。客户可能认为改个程序，就像改个Excel一样简单省事，甚至会使用可动用的一切权利和资源来推行变更。好吧，我承认这样的客户我遇到过很多。当我向客户解释过变更的代价并提供备选方案后，也就只能等待客户的选择了，这多少有些运数的成分，但也是无奈之举。 7、仅仅靠加班应对进度落后进度落后并不可怕，可怕的是仅靠加班来追赶进度。这是问题的关键，长时间的赶工仍然无法赶上进度，这只意味着项目有某种更深层次的问题，已经不是单开赶工可以解决的了。留意那些长时间加班的项目，他们往往在管理上存在很大问题，发现这些问题，在你成为PM时，不要犯类似错误。 怎样在复杂代码中找bug？ 放大现象，有些bug现象不太明显，那么就想办法增大它的破坏性，把现象放大。这只是个思路，具体怎么放大只能根据具体的代码来定。比如：美剧《豪斯医生》里有一集，怀疑病人心肺有问题，就让病人去跑步机上跑步，加重心肺负担，从而放大症状。 二分法定位，把程序逻辑一点点注释掉，看看还会不会出问题，类似二分查找的方法，逐步缩小问题范围。 模拟现场，有时候我会问自己，如果我要实现bug描述的现象我要怎么写代码才行？比如：我遇到一个死锁问题，但是检查代码发现所有的锁都是配对的，没有忘记解锁的地方，而且锁很简单就是一个普通的临界段，保护几行赋值语句而已。这样的代码怎么写才能让他死锁呢？我想如果让我故意制造这样一个现象，只有在上锁的时候强制杀掉线程了，既然这样就可以去看看有谁强杀线程了没有。 制作工具，针对某些bug编写一些调试辅助工具。比如，我那个系统没有完善的崩溃报告，虽然也有dump，但是分析出来的callstack经常不准。于是我为解决崩溃问题编写了个工具，会自动扫描代码，在每个函数入口和出口插入log，以此来定位崩溃点。 掩盖问题，虽然这样做有点不厚道，但是有时不得不这么做。有些bug找不到真正的root cause，但是又要在规定时间内解决，那么我们就可以治疗症状而不去找病因。比如用try catch掩盖一些奇怪的崩溃。不到万不得已不要这么干，未来可能会付出更大代价。 减少 bug 的第一步，是提升自己的程序员素养，努力不给自己和别人找麻烦。 程序员新人怎样在复杂代码中找bug？ 另外，团队协作也很重要，前期的技术方案和设计评审、代码审查，对减少一些重大的错误和弱智的 bug 都非常有好处。 与几个有经验的程序员一起评审一个技术方案，常常会发现一些重大的问题，比如为什么用缓存，为什么做持久化，高并发下怎么应对，这部分设计支持线程重入吗，这个循环为什么设置成10分钟，这个超时设置为什么是60秒，传输协议加密了吗，等等。很多方案可能会仅限于解决当前的问题，但有经验的程序员却能透过时间的重重迷雾，发现这个方案在未来某个时间点可能爆发的问题。这就是评审的力量。]]></content>
      <categories>
        <category>Essay</category>
      </categories>
      <tags>
        <tag>Coding</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL常见性能优化]]></title>
    <url>%2F2017%2F04%2F11%2FMySQL%E5%B8%B8%E8%A7%81%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[优化Group By语句默认情况下，MySQL 排序所有GROUP BY col1，col2，….。查询的方法如同在查询中指定ORDER BY col1，col2，…。如果显式包括一个包含相同的列的ORDER BY子句，MySQL 可以毫不减速地对它进行优化，尽管仍然进行排序。如果查询包括GROUP BY 但你想要避免排序结果的消耗，你可以指定ORDER BY NULL禁止排序。 优化Order by语句在某些情况中，MySQL 可以使用一个索引来满足ORDER BY 子句，而不需要额外的排序。where 条件和order by 使用相同的索引，并且order by 的顺序和索引顺序相同，并且order by 的字段都是升序或者都是降序。 优化insert语句如果你同时从同一客户插入很多行，使用多个值表的INSERT 语句。这比使用分开 INSERT 语句快(在一些情况中几倍)。 1mysql&gt; insert into test values(1,2),(1,3),(1,4)… 如果你从不同客户插入很多行，能通过使用INSERT DELAYED 语句得到更高的速度。Delayed 的含义是让insert 语句马上执行，其实数据都被放在内存的队列中，并没有真正的写入磁盘；这比每条语句都分别插入要快的多；LOW_PRIORITY刚好相反，在所有其他用户对表的读写完成后才进行插入。将索引文件和数据文件分在不同的磁盘上存放（利用建表中的选项）；如果进行批量插入，可以增加bulk_insert_buffer_size 变量值的方法来提高速度，但是，这只能对myisam表使用当从一个文本文件装载一个表时，使用LOAD DATA INFILE。这通常比使用很多INSERT语句快20倍；根据应用情况使用replace 语句代替insert；根据应用情况使用ignore 关键字忽略重复记录。 大批量插入数据 对于Myisam 类型的表，可以通过以下方式快速的导入大量的数据。ALTER TABLE tblname DISABLE KEYS;这两个命令用来打开或者关闭Myisam 表非唯一索引的更新。在导入大量的数据到一个非空的Myisam 表时，通过设置这两个命令，可以提高导入的效率。对于导入大量数据到一个空的Myisam 表，默认就是先导入数据然后才创建索引的，所以不用进行设置。 而对于Innodb 类型的表，这种方式并不能提高导入数据的效率。对于Innodb 类型的表，我们有以下几种方式可以提高导入的效率：a. 因为Innodb 类型的表是按照主键的顺序保存的，所以将导入的数据按照主键的顺序排列，可以有效的提高导入数据的效率。如果Innodb 表没有主键，那么系统会默认创建一个内部列作为主键，所以如果可以给表创建一个主键，将可以利用这个优势提高导入数据的效率。b. 在导入数据前执行SET UNIQUE_CHECKS=0，关闭唯一性校验，在导入结束后执行SETUNIQUE_CHECKS=1，恢复唯一性校验，可以提高导入的效率。c. 如果应用使用自动提交的方式，建议在导入前执行SET AUTOCOMMIT=0，关闭自动提交，导入结束后再执行SET AUTOCOMMIT=1，打开自动提交，也可以提高导入的效率。 查询的优化读为主可以设置low_priority_updates=1，写的优先级调低，告诉MYSQL尽量先处理读求为查询缓存优化你的查询大多数的MySQL服务器都开启了查询缓存。这是提高性最有效的方法之一，而且这是被MySQL的数据库引擎处理的。当有很多相同的查询被执行了多次的时候，这些查询结果会被放到一个缓存中，这样，后续的相同的查询就不用操作表而直接访问缓存结果了。这里最主要的问题是，对于程序员来说，这个事情是很容易被忽略的。因为，我们某些查询语句会让MySQL不使用缓存。请看下面的示例：// 查询缓存不开启 拆分大的 DELETE 或 INSERT 语句如果你需要在一个在线的网站上去执行一个大的 DELETE 或 INSERT 查询，你需要非常小心，要避免你的操作让你的整个网站停止相应。因为这两个操作是会锁表的，表一锁住了，别的操作都进不来了。Apache 会有很多的子进程或线程。所以，其工作起来相当有效率，而我们的服务器也不希望有太多的子进程，线程和数据库链接，这是极大的占服务器资源的事情，尤其是内存。如果你把你的表锁上一段时间，比如30秒钟，那么对于一个有很高访问量的站点来说，这30秒所积累的访问进程/线程，数据库链接，打开的文件数，可能不仅仅会让你泊WEB服务Crash，还可能会让你的整台服务器马上掛了。所以，如果你有一个大的处理，你定你一定把其拆分，使用 LIMIT 条件是一个好的方法。 where语句的优化 尽量避免在 where 子句中对字段进行表达式操作 1select id from uinfo_jifen where jifen/60 &gt; 10000; 优化后: 1Select id from uinfo_jifen where jifen&gt;600000; 应尽量避免在where子句中对字段进行函数操作，这将导致mysql放弃使用索引 1select uid from imid where datediff(create_time,'2011-11-22')=0 优化后: 1select uid from imid where create_time&gt; ='2011-11-21‘ and create_time&lt;‘2011-11-23’; 索引的优化MySQL只有对以下操作符才使用索引：&lt;，&lt;=，=，&gt;，&gt;=，BETWEEN，IN，以及某些时候的LIKE。尽量不要写!=或者&lt;&gt;的sql，用between或&gt; and &lt;代替，否则可能用不到索引Order by 、Group by 、Distinct 最好在需要这个列上建立索引，利于索引排序尽量利用mysql索引排序没办法的情况下，使用强制索引Force index(index_name)尽量避勉innodb用非常大尺寸的字段作为主键较频繁的作为查询条件的字段应该创建索引;选择性高的字段比较适合创建索引;作为表关联字段一般都需要创索引.更新非常频繁的字段不适合创建索引;不会出现在 WHERE 子句中的字段不该创建索引.选择性太低的字段不适合单独创建索引 尽量不要用子查询12mysql&gt; explain select uid_,count(*) from smember_6 where uid_ in (select uid_ from alluid) group by uid_;--| id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra |+----+--------------------+-----------+-------+---------------+---------+---------+------+----------+--------------------------+| 1 | PRIMARY | smember_6 | index | NULL | PRIMARY | 8 | NULL | 53431264 | Using where; Using index | | 2 | DEPENDENT SUBQUERY | alluid | ALL | NULL | NULL | NULL | NULL | 2448 | Using where | 优化后: 12mysql&gt; explain select a.uid_,count(*) from smember_6 a,alluid b where a.uid_=b.uid_ group by uid_;--| id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra |+----+-------------+-------+------+---------------+---------+---------+------------+------+---------------------------------+| 1 | SIMPLE | b | ALL | NULL | NULL | NULL | NULL | 2671 | Using temporary; Using filesort | | 1 | SIMPLE | a | ref | PRIMARY | PRIMARY | 4 | ssc.b.uid_ | 1 | Using index Join的优化如果你的应用程序有很多 JOIN 查询，你应该确认两个表中Join的字段是被建过索引的。这样，MySQL内部会启动为你优化Join的SQL语句的机制。而且，这些被用来Join的字段，应该是相同的类型的。例如：如果你要把 DECIMAL 字段和一个 INT 字段Join在一起，MySQL就无法使用它们的索引。对于那些STRING类型，还需要有相同的字符集才行。（两个表的字符集有可能不一样） 表的优化尽可能的使用 NOT NULL除非你有一个很特别的原因去使用 NULL 值，你应该总是让你的字段保持 NOT NULL。不要以为 NULL 不需要空间，其需要额外的空间，并且，在你进行比较的时候，你的程序会更复杂。当然，这里并不是说你就不能使用NULL了，现实情况是很复杂的，依然会有些情况下，你需要使用NULL值。下面摘自MySQL自己的文档：“NULL columns require additional space in the row to record whether their values are NULL. For MyISAM tables, each NULL column takes one bit extra, rounded up to the nearest byte.” 固定长度的表会更快如果表中的所有字段都是“固定长度”的，整个表会被认为是 “static” 或 “fixed-length”。 例如，表中没有如下类型的字段： VARCHAR，TEXT，BLOB。只要你包括了其中一个这些字段，那么这个表就不是“固定长度静态表”了，这样，MySQL 引擎会用另一种方法来处理。固定长度的表会提高性能，因为MySQL搜寻得会更快一些，因为这些固定的长度是很容易计算下一个数据的偏移量的，所以读取的自然也会很快。而如果字段不是定长的，那么，每一次要找下一条的话，需要程序找到主键。并且，固定长度的表也更容易被缓存和重建。不过，唯一的副作用是，固定长度的字段会浪费一些空间，因为定长的字段无论你用不用，他都是要分配那么多的空间。 垂直分割“垂直分割”是一种把数据库中的表按列变成几张表的方法，这样可以降低表的复杂度和字段的数目，从而达到优化的目的。（以前，在银行做过项目，见过一张表有100多个字段，很恐怖）示例一：在Users表中有一个字段是家庭地址，这个字段是可选字段，相比起，而且你在数据库操作的时候除了个人信息外，你并不需要经常读取或是改写这个字段。那么，为什么不把他放到另外一张表中呢？ 这样会让你的表有更好的性能，大家想想是不是，大量的时候，我对于用户表来说，只有用户ID，用户名，口令，用户角色等会被经常使用。小一点的表总是会有好的性能。示例二： 你有一个叫 “last_login” 的字段，它会在每次用户登录时被更新。但是，每次更新时会导致该表的查询缓存被清空。所以，你可以把这个字段放到另一个表中，这样就不会影响你对用户ID，用户名，用户角色的不停地读取了，因为查询缓存会帮你增加很多性能。另外，你需要注意的是，这些被分出去的字段所形成的表，你不会经常性地去Join他们，不然的话，这样的性能会比不分割时还要差，而且，会是极数级的下降。 越小的列会越快对于大多数的数据库引擎来说，硬盘操作可能是最重大的瓶颈。所以，把你的数据变得紧凑会对这种情况非常有帮助，因为这减少了对硬盘的访问。参看 MySQL 的文档 Storage Requirements 查看所有的数据类型。如果一个表只会有几列罢了（比如说字典表，配置表），那么，我们就没有理由使用 INT 来做主键，使用 MEDIUMINT, SMALLINT 或是更小的 TINYINT 会更经济一些。如果你不需要记录时间，使用 DATE 要比 DATETIME 好得多。当然，你也需要留够足够的扩展空间，不然，你日后来干这个事，你会死的很难看，参看Slashdot的例子（2009年11月06日），一个简单的ALTER TABLE语句花了3个多小时，因为里面有一千六百万条数据。]]></content>
      <categories>
        <category>Essay</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git Commit message 的写法规范之《Angular 规范》]]></title>
    <url>%2F2017%2F04%2F11%2FGit-Commit-message-%E7%9A%84%E5%86%99%E6%B3%95%E8%A7%84%E8%8C%83%E4%B9%8B%E3%80%8AAngular-%E8%A7%84%E8%8C%83%E3%80%8B%2F</url>
    <content type="text"><![CDATA[目前，社区有多种 Commit message 的写法规范。本文介绍《Angular 规范》，这是目前使用最广的写法，比较合理和系统化，并且有配套的工具。 一、Commit message 的作用格式化的Commit message，有几个好处。 （1）提供更多的历史信息，方便快速浏览。比如，下面的命令显示上次发布后的变动，每个commit占据一行。你只看行首，就知道某次 commit 的目的。 1$ git log &lt;last tag&gt; HEAD --pretty=format:%s （2）可以过滤某些commit（比如文档改动），便于快速查找信息。比如，下面的命令仅仅显示本次发布新增加的功能。 1$ git log &lt;last release&gt; HEAD --grep feature （3）可以直接从commit生成Change log。Change Log 是发布新版本时，用来说明与上一个版本差异的文档，详见后文。 二、Commit message 的格式每次提交，Commit message 都包括三个部分：Header，Body 和 Footer。 12345&lt;type&gt;(&lt;scope&gt;): &lt;subject&gt;// 空一行&lt;body&gt;// 空一行&lt;footer&gt; 其中，Header 是必需的，Body 和 Footer 可以省略。不管是哪一个部分，任何一行都不得超过72个字符（或100个字符）。这是为了避免自动换行影响美观。 2.1 HeaderHeader部分只有一行，包括三个字段：type（必需）、scope（可选）和subject（必需）。 （1）type type用于说明 commit 的类别，只允许使用下面7个标识。 feat：新功能（feature） fix：修补bug docs：文档（documentation） style： 格式（不影响代码运行的变动） refactor：重构（即不是新增功能，也不是修改bug的代码变动） test：增加测试 chore：构建过程或辅助工具的变动 如果type为feat和fix，则该 commit 将肯定出现在 Change log 之中。其他情况（docs、chore、style、refactor、test）由你决定，要不要放入 Change log，建议是不要。 （2）scopescope用于说明 commit 影响的范围，比如数据层、控制层、视图层等等，视项目不同而不同。 （3）subjectsubject是 commit 目的的简短描述，不超过50个字符。以动词开头，使用第一人称现在时，比如change，而不是changed或changes第一个字母小写结尾不加句号（.） 2.2 BodyBody 部分是对本次 commit 的详细描述，可以分成多行。下面是一个范例。 1234567More detailed explanatory text, if necessary. Wrap it to about 72 characters or so. Further paragraphs come after blank lines.- Bullet points are okay, too- Use a hanging indent 有两个注意点。（1）使用第一人称现在时，比如使用change而不是changed或changes。（2）应该说明代码变动的动机，以及与以前行为的对比。 2.3 FooterFooter 部分只用于两种情况。 （1）不兼容变动如果当前代码与上一个版本不兼容，则 Footer 部分以BREAKING CHANGE开头，后面是对变动的描述、以及变动理由和迁移方法。 1234567891011121314151617BREAKING CHANGE: isolate scope bindings definition has changed. To migrate the code follow the example below: Before: scope: &#123; myAttr: &apos;attribute&apos;, &#125; After: scope: &#123; myAttr: &apos;@&apos;, &#125; The removed `inject` wasn&apos;t generaly useful for directives so there should be no code using it. （2）关闭 Issue如果当前 commit 针对某个issue，那么可以在 Footer 部分关闭这个 issue 。 1Closes #234 也可以一次关闭多个 issue 。 1Closes #123, #245, #992 2.4 Revert还有一种特殊情况，如果当前 commit 用于撤销以前的 commit，则必须以revert:开头，后面跟着被撤销 Commit 的 Header。 123revert: feat(pencil): add &apos;graphiteWidth&apos; optionThis reverts commit 667ecc1654a317a13331b17617d973392f415f02. Body部分的格式是固定的，必须写成This reverts commit &lt;hash&gt;.，其中的hash是被撤销 commit 的 SHA 标识符。如果当前 commit 与被撤销的 commit，在同一个发布（release）里面，那么它们都不会出现在 Change log 里面。如果两者在不同的发布，那么当前 commit，会出现在 Change log 的Reverts小标题下面。 三、CommitizenCommitizen是一个撰写合格 Commit message 的工具。安装命令如下。 1$ npm install -g commitizen 然后，在项目目录里，运行下面的命令，使其支持 Angular 的 Commit message 格式。 1$ commitizen init cz-conventional-changelog --save --save-exact 以后，凡是用到git commit命令，一律改为使用git cz。这时，就会出现选项，用来生成符合格式的 Commit message。 四、validate-commit-msgvalidate-commit-msg 用于检查 Node 项目的 Commit message 是否符合格式。它的安装是手动的。首先，拷贝下面这个JS文件，放入你的代码库。文件名可以取为validate-commit-msg.js。接着，把这个脚本加入 Git 的 hook。下面是在package.json里面使用 ghooks，把这个脚本加为commit-msg时运行。 12345&quot;config&quot;: &#123; &quot;ghooks&quot;: &#123; &quot;commit-msg&quot;: &quot;./validate-commit-msg.js&quot; &#125;&#125; 然后，每次git commit的时候，这个脚本就会自动检查 Commit message 是否合格。如果不合格，就会报错。 123$ git add -A $ git commit -m &quot;edit markdown&quot; INVALID COMMIT MSG: does not match &quot;&lt;type&gt;(&lt;scope&gt;): &lt;subject&gt;&quot; ! was: edit markdown 五、生成 Change log如果你的所有 Commit 都符合 Angular 格式，那么发布新版本时， Change log 就可以用脚本自动生成（例1，例2，例3）。生成的文档包括以下三个部分。 123New featuresBug fixesBreaking changes. 每个部分都会罗列相关的 commit ，并且有指向这些 commit 的链接。当然，生成的文档允许手动修改，所以发布前，你还可以添加其他内容。conventional-changelog 就是生成 Change log 的工具，运行下面的命令即可。 123$ npm install -g conventional-changelog$ cd my-project$ conventional-changelog -p angular -i CHANGELOG.md -w 上面命令不会覆盖以前的 Change log，只会在CHANGELOG.md的头部加上自从上次发布以来的变动。如果你想生成所有发布的 Change log，要改为运行下面的命令。 1$ conventional-changelog -p angular -i CHANGELOG.md -w -r 0 为了方便使用，可以将其写入package.json的scripts字段。 12345&#123; &quot;scripts&quot;: &#123; &quot;changelog&quot;: &quot;conventional-changelog -p angular -i CHANGELOG.md -w -r 0&quot; &#125;&#125; 以后，直接运行下面的命令即可。 1$ npm run changelog 转自http://www.ruanyifeng.com/blog/2016/01/commit_message_change_log.html]]></content>
      <categories>
        <category>Essay</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker可视化管理工具Shipyard安装与配置]]></title>
    <url>%2F2017%2F04%2F11%2FDocker%E5%8F%AF%E8%A7%86%E5%8C%96%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7Shipyard%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[文章来源： Shipyard Automated Deployment Shipyard简介Shipyard是一个集成管理docker容器、镜像、Registries的系统，它具有以下特点： 支持多节点的集成管理 可动态加载节点 可托管node下的容器 环境准备下载镜像12345$ docker pull rethinkdb$ docker pull microbox/etcd$ docker pull shipyard/docker-proxy$ docker pull swarm $ docker pull shipyard/shipyard 自动安装注意：这将会暴露Docker Engine的管理端口2375。如果此节点在安全网络外部可以访问，建议使用TLS。 下载自动部署Shell脚本1$ curl -sSL https://shipyard-project.com/deploy | bash -s 自动部署脚本中， 包括以下参数： ACTION： 表示可以使用的指令，它包括以下选项。 deploy， 默认值， 表示自动安装部署Shipyard管理工具及相关应用 upgrade，更新已存在的实例（注意：你要保持相同的系统环境、变量来部署同样的配置） node， 部署Swarm的一个新节点 remove， 已存在的shipyard实例 DISCOVERY: 集群系统采用Swarm进行采集和管理(在节点管理中可以使用‘node’) IMAGE: 镜像，默认使用shipyard的镜像 PREFIX: 容器名字的前缀 SHIPYARD_ARGS: 容器的常用参数 TLS_CERT_PATH: TLS证书路径 PORT: 主程序监听端口 (默认端口: 8080) PROXY_PORT: 代理端口 (默认: 2375) 使用镜像Shipyard允许您采取指定的镜像来部署实例，比如以下的测试版本，你也已这样做： 1$ curl -sSL https://shipyard-project.com/deploy | IMAGE=shipyard/shipyard:test bash -s 使用前缀你可以在部署Shipyard管理工具时，自定义你想要的前缀，比如 1$ curl -sSL https://shipyard-project.com/deploy | PREFIX=shipyard-test bash -s 使用运行参数这里增加一些shipyard运行参数，你可以像这样进行调整： 1$ curl -sSL https://shipyard-project.com/deploy | SHIPYARD_ARGS=&quot;--ldap-server=ldap.example.com --ldap-autocreate-users&quot; bash -s 使用安全认证(TLS证书)启用安全加密通讯协议（TLS）对Shipyard进行部署，包括代理（docker-proxy）、swarm集群、shipyard管理平台的配置，这是一个配置规范。证书必须采用以下命名规范： ca.pem: 安全认证证书 server.pem: 服务器证书 server-key.pem: 服务器私有证书 cert.pem: 客户端证书 key.pem: 客户端证书的key 注意：证书将被放置在一个单独的安全认证docker容器中，并在各个组成部分之间共享。如果需要调试，可以将此容器连接到调试容器。数据容器名称为$PREFIX-certs。 12345678$ docker run --rm \ -v $(pwd)/certs:/certs \ ehazlett/certm \ -d /certs \ bundle \ generate \ -o shipyard \ --host proxy \ --host 127.0.0.1 你也可以在部署时，指定TLS_CERT_PATH参数： 1$ curl -sSL https://shipyard-project.com/deploy | TLS_CERT_PATH=$(pwd)/certs bash -s 增加Swarm节点Shipyard管理的Swarm节点部署脚本将自动的安装key/value存储系统（etcd系统），用于进行服务发现， 相关的工具还有Consul、Zookeeper。增加一个节点到swarm集群，你可以通过以下的节点部署脚本： 1$ curl -sSL https://shipyard-project.com/deploy | ACTION=node DISCOVERY=etcd://10.0.1.10:4001 bash -s 注意：10.0.1.10该ip地址为部署Ectd系统所在主机的IP地址，你需要根据你的部署位置进行修改。 删除Shipyard管理工具如果你要删除Shipyard部署的容器，你可以使用以下脚本进行删除。 1$ curl -sSL https://shipyard-project.com/deploy | ACTION=remove bash -s 手动安装数据存储Shipyard使用RethinkDB做为数据存储工具， 我们需要先运行RethinkDB容器。 123456$ docker run \ -ti \ -d \ --restart=always \ --name shipyard-rethinkdb \ rethinkdb 服务发现为了启用Swarm leader选择，我们必须使用来自Swarm容器的外部键值存储。此处，我们使用Etcd作为服务发现工具。可以选用的服务发现工具还有Consul、Zookeeper等。 123456789$ docker run \ -ti \ -d \ -p 4001:4001 \ -p 7001:7001 \ --restart=always \ --name shipyard-discovery \ microbox/etcd:latest \ -name discovery Docker代理服务默认情况下，Docker引擎只侦听套接字。 我们可以重新配置引擎以使用TLS，或者您可以使用代理容器。 这是一个非常轻量级的容器，它只是将请求从TCP转发到Docker监听的Unix套接字。 12345678910$ docker run \ -ti \ -d \ -p 2375:2375 \ --hostname=$HOSTNAME \ --restart=always \ --name shipyard-proxy \ -v /var/run/docker.sock:/var/run/docker.sock \ -e PORT=2375 \ shipyard/docker-proxy:latest Swarm管理节点1234567$ docker run \ -ti \ -d \ --restart=always \ --name shipyard-swarm-manager \ swarm:latest \ manage --host tcp://0.0.0.0:3375 etcd://&lt;IP-OF-HOST&gt;:4001 Swarm Agent节点1234567$ docker run \ -ti \ -d \ --restart=always \ --name shipyard-swarm-agent \ swarm:latest \ join --addr &lt;ip-of-host&gt;:2375 etcd://&lt;ip-of-host&gt;:4001 Shipyard管理工具1234567891011$ docker run \ -ti \ -d \ --restart=always \ --name shipyard-controller \ --link shipyard-rethinkdb:rethinkdb \ --link shipyard-swarm-manager:swarm \ -p 8080:8080 \ shipyard/shipyard:latest \ server \ -d tcp://swarm:3375]]></content>
      <categories>
        <category>Collection</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JAVA不借助中间变量交换2个变量的值]]></title>
    <url>%2F2017%2F04%2F09%2FJAVA%E4%B8%8D%E5%80%9F%E5%8A%A9%E4%B8%AD%E9%97%B4%E5%8F%98%E9%87%8F%E4%BA%A4%E6%8D%A22%E4%B8%AA%E5%8F%98%E9%87%8F%E7%9A%84%E5%80%BC%2F</url>
    <content type="text"><![CDATA[1234567891011121314151617public static void main(String[] args) &#123; /*方法一*/ int a = 3; int b = 4; a=a+b; b=a-b; a=a-b; System.out.println("a="+a+",b="+b); /*方法二利用位运算交换，效率很高*/ int aa=3; int bb=4; aa=aa^bb; bb=bb^aa; aa=aa^bb; System.out.println("aa="+aa+",bb="+bb);&#125;]]></content>
      <categories>
        <category>Essay</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring模块及生态支持汇总]]></title>
    <url>%2F2017%2F04%2F09%2FSpring%E6%A8%A1%E5%9D%97%E5%8F%8A%E7%94%9F%E6%80%81%E6%94%AF%E6%8C%81%E6%B1%87%E6%80%BB%2F</url>
    <content type="text"><![CDATA[一、Spring模块（1）核心容器 Spring-Core：核心工具类，Spring其他模块大量使用Spring-Core Spring-Bean：Spring定义Bean的支持 Spring-Context：运行时Spring容器 Spring-Context-Support：Spring容器对第三方包的集成支持 Spring-Expression：使用表达式语言在运行时查询和操作对象 （2）AOP Spring-Aop：基于代理的AOP支持 Spring-Aspects：基于AspectJ的AOP支持 （3）消息(message) Spring-Messaging：对消息架构和协议的支持 （4）Web Spring-Web：提供基础的Web集成功能，在Web项目中提供Spring的容器 Spring-Webmvc：提供基于Servlet的Spring MVC Spring-WebSocket：提供WebSocket功能 Spring-Webmvc-Portlet：提供Portlet环境支持 （5）数据访问/集成（Data Access/Integration） Spring-JDBC：提供以JDBC访问数据库的支持 Spring-TX：提供编程式和声明式的事务支持 Spring-ORM：提供对对象/关系映射技术的支持 Spring-OXM：提供对对象/xml映射技术的支持 Spring-JMS：提供对JMS的支持 二、Spring的生态Spring发展到现在已经不仅仅是Spring框架本身的内容，Spring目前提供了大量的基于Spring的项目，可以用来更深入地降低我们的开发难度，提高开发效率。目前Spring的生态里主要有以下项目，我们可以根据自己项目的需要来选择使用相应的项目： Spring Boot：使用默认开发配置来实现快捷开发 Spring XD：用来简化大数据应用开发 Spring Cloud：为分布式系统开发提供工具集 Spring Data：对主流的关系型和Nosql数据库的支持 Spring Integration：通过消息机制对企业集成模式（EIP）的支持 Spring Batch：简化及优化大量数据的批处理操作 Spring Security：通过认证和授权保护应用 Spring HATEOAS：基于HATEOAS原则简化REST服务开发 Spring Social：于社交网络API（如Facebook、新浪微博等）的集成 Spring AMQP：对基于AMQP的消息的支持 Spring Mobile：提供对手机设备检测的功能，给不同的设备返回不同的页面的支持 Spring for Android：主要提供在Android上消费Restful API的功能 Spring Web Flow：基于Spring MVC提供基于向导流程式的Web应用开发 Spring Web Services：提供基于协议有限的SOAP/Web服务 Spring LDAP：简化LDAP开发 Spring Session：提供一个API及实现来管理用户会话信息]]></content>
      <categories>
        <category>Essay</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java中创建对象的5种不同方法]]></title>
    <url>%2F2017%2F04%2F08%2FJava%E4%B8%AD%E5%88%9B%E5%BB%BA%E5%AF%B9%E8%B1%A1%E7%9A%845%E7%A7%8D%E4%B8%8D%E5%90%8C%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[作为Java开发者，我们每天都会创建大量的对象，但是，我们总是使用管理依赖系统（如Spring框架）来创建这些对象。其实还有其他方法可以创建对象，在接下来的文章中我会进行详细介绍。1.使用new关键字这是最常见的创建对象的方法，并且也非常简单。通过使用这种方法我们可以调用任何我们需要调用的构造函数。12Employee emp1 = new Employee();0: new #19 // class org/programming/mitra/exercises/Employee 3: dup 4: invokespecial #21 // Method org/programming/mitra/exercises/Employee."":V 2.使用class类的newInstance方法我们也可以使用class类的newInstance方法来创建对象。此newInstance方法调用无参构造函数以创建对象。我们可以通过newInstance 用以下方式创建对象：1Employee emp2 = (Employee) Class.forName("org.programming.mitra.exercises.Employee").newInstance; 或者12Employee emp2 = Employee.class.newInstance;51: invokevirtual #70 // Method java/lang/Class.newInstance:Ljava/lang/Object; 3.使用构造函数类的 newInstance方法与使用class类的newInstance方法相似，java.lang.reflect.Constructor类中有一个可以用来创建对象的newInstance函数方法。通过使用这个newInstance方法我们也可以调用参数化构造函数和私有构造函数。Constructor111: invokevirtual #80 // Method java/lang/reflect/Constructor.newInstance:([Ljava/lang/Object;)Ljava/lang/Object;这些 newInstance 方法被认为是创建对象的反射手段。实际上，内部类的newInstance方法使用构造函数类的 newInstance 方法。这就是为什么后者是首选并且使用不同的框架如Spring, Hibernate, Struts等。4.使用clone方法实际上无论何时我们调用clone 方法，JAVA虚拟机都为我们创建了一个新的对象并且复制了之前对象的内容到这个新的对象中。使用 clone方法创建对象不会调用任何构造函数。为了在对象中使用clone方法，我们需要在其中实现可克隆类型并定义clone方法。12Employee emp4 = (Employee) emp3.clone();162: invokevirtual #87 // Method org/programming/mitra/exercises/Employee.clone Ljava/lang/Object; 5.使用反序列化无论何时我们对一个对象进行序列化和反序列化，JAVA虚拟机都会为我们创建一个单独的对象。在反序列化中，JAVA虚拟机不会使用任何构造函数来创建对象。对一个对象进行序列化需要我们在类中实现可序列化的接口。123ObjectInputStream in = new ObjectInputStream(new FileInputStream(&quot;data.obj&quot;)); Employee emp5 = (Employee) in.readObject();invokevirtual #118 // Method java/io/ObjectInputStream.readObject:Ljava/lang/Object; 正如我们在以上的字节代码片段中所看到的，除第一种被转换为一个新的函数和一个 invokespecial 指令以外，其它4种方法都被调用并转换为invokevirtual。示例让我们来看看准备创建对象的 Employee 类：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162class Employee implements Cloneable, Serializable &#123; private static final long serialVersionUID = 1L; private String name; public Employee() &#123; System.out.println("Employee Constructor Called..."); &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; @Override public int hashCode() &#123; final int prime = 31; int result = 1; result = (prime * result) + ((name == null) ? 0 : name.hashCode); return (result); &#125; @Override public boolean equals(Object obj) &#123; if (this == obj) &#123; return (true); &#125; if (obj == null) &#123; return (false); &#125; if (getClass != obj.getClass) &#123; return (false); &#125; Employee other = (Employee) obj; if (name == null) &#123; if (other.name != null) &#123; return (false); &#125; &#125; else if (!name.equals(other.name)) &#123; return (false); &#125; return (true); &#125; @Override public String toString() &#123; return ("Employee [name=" + name + "]"); &#125; @Override public Object clone() &#123; Object obj = null; try &#123; obj = super.clone; &#125; catch (CloneNotSupportedException e) &#123; e.printStackTrace; &#125; return (obj); &#125;&#125; 在下面的Java程序中我们用5种方式来创建 Employee对象。12345678910111213141516public class ObjectCreation &#123; public static void main(String... args) throws Exception &#123; // By using new keyword Employee emp1 = new Employee(); emp1.setName("Naresh"); System.out.println(emp1 + ", hashcode : " + emp1.hashCode()); // By using Class class's newInstance method Employee emp2 = (Employee) Class.forName("org.programming.mitra.exercises.Employee").newInstance(); // Or we can simply do this // Employee emp2 = Employee.class.newInstance(); emp2.setName("Rishi"); System.out.println(emp2 + ", hashcode : " + emp2.hashCode()); // By using Constructor class's newInstance method Constructor &#125;&#125; 此程序输出结果如下：1234Employee Constructor Called… Employee [name=Naresh], hashcode : -1968815046 Employee Constructor Called… Employee [name=Rishi], hashcode : 78970652 Employee Constructor Called… Employee [name=Yogesh], hashcode : -1641292792 Employee [name=Atul], hashcode : 2051657 Employee [name=Akash], hashcode : 63313419]]></content>
      <categories>
        <category>Essay</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MYSQL建表规约]]></title>
    <url>%2F2017%2F04%2F08%2FMYSQL%E5%BB%BA%E8%A1%A8%E8%A7%84%E7%BA%A6%2F</url>
    <content type="text"><![CDATA[【强制】表达是与否概念的字段，必须使用 is_xxx 的方式命名，数据类型是 unsigned tinyint（ 1 表示是，0 表示否），此规则同样适用于 odps 建表。说明：任何字段如果为非负数，必须是 unsigned。举例：is_star tinyint unsigned DEFAULT NULL COMMENT ‘项目状态（1 表示是，0 表示否）’ 【强制】表名、字段名必须使用小写字母或数字；禁止出现数字开头，禁止两个下划线中间只出现数字。数据库字段名的修改代价很大，因为无法进行预发布，所以字段名称需要慎重考虑。正例：getter_admin，task_config，level3_name反例：GetterAdmin，taskConfig，level_3_name 【强制】表名不使用复数名词。说明：表名应该仅仅表示表里面的实体内容，不应该表示实体数量，对应于 DO 类名也是单数形式，符合表达习惯。 【强制】禁用保留字，如 desc、range、match、delayed 等，参考官方保留字。 【强制】唯一索引名为 uk字段名；普通索引名则为 idx字段名。说明：uk 即 unique key；idx 即 index 的简称。 【强制】小数类型为 decimal，禁止使用 float 和 double。说明：float 和 double 在存储的时候，存在精度损失的问题，很可能在值的比较时，得到不正确的结果。如果存储的数据范围超过 decimal 的范围，建议将数据拆成整数和小数分开存储。 【强制】如果存储的字符串长度几乎相等，使用 CHAR 定长字符串类型。 【强制】varchar 是可变长字符串，不预先分配存储空间，长度不要超过 5000，如果存储长度大于此值，定义字段类型为 TEXT，独立出来一张表，用主键来对应，避免影响其它字段索引效率。 【强制】表必备三字段：id, gmt_create, gmt_modified。说明：其中 id 必为主键，类型为 unsigned bigint、单表时自增、步长为 1； 分表时改为从TDDL Sequence 取值，确保分表之间的全局唯一。gmt_create, gmt_modified 的类型均为date_time 类型。 【推荐】表的命名最好是加上“业务名称_表的作用”，避免上云梯后，再与其它业务表关联时有混淆。正例：tiger_task / tiger_reader / mpp_config 【推荐】库名与应用名称尽量一致。 【推荐】如果修改字段含义或对字段表示的状态追加时，需要及时更新字段注释。 【推荐】字段允许适当冗余，以提高性能，但是必须考虑数据同步的情况。冗余字段应遵循：1）不是频繁修改的字段。2）不是 varchar 超长字段，更不能是 text 字段。正例：各业务线经常冗余存储商品名称，避免查询时需要调用 IC 服务获取。 【推荐】单表行数超过 500 万行或者单表容量超过 2GB，才推荐进行分库分表。说明：如果预计三年后的数据量根本达不到这个级别，请不要在创建表时就分库分表。反例：某业务三年总数据量才 2 万行，却分成 1024 张表，问：你为什么这么设计？答：分 1024张表，不是标配吗？【参考】合适的字符存储长度，不但节约数据库表空间、节约索引存储，更重要的是提升检索速度。正例：人的年龄用 unsigned tinyint（表示范围 0-255，人的寿命不会超过 255 岁）；海龟就必须是 smallint，但如果是太阳的年龄，就必须是 int；如果是所有恒星的年龄都加起来，那么就必须使用 bigint。]]></content>
      <categories>
        <category>Essay</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL里面这五个非常非常有用的东西]]></title>
    <url>%2F2017%2F04%2F08%2FMySQL%E9%87%8C%E9%9D%A2%E8%BF%99%E4%BA%94%E4%B8%AA%E9%9D%9E%E5%B8%B8%E9%9D%9E%E5%B8%B8%E6%9C%89%E7%94%A8%E7%9A%84%E4%B8%9C%E8%A5%BF%2F</url>
    <content type="text"><![CDATA[MySQL是非常流行的关系型数据库，虽然拥有的SQL语法大部分是符合ANSI SQL标准的，但是它自身还是携带了很多优秀的、私有的语句和指示符，今天我们就来分析一下。 EXPLAIN难度指数：★ ★ ★ ★ ★推荐指数：★ ★ ★ ★ ★当我们网站或者接口访问频率越来越大，这时如果我们的相关SQL语句执行时间很长的话，就很容易造成网站或者接口响应慢的情况，那么使用explain语句，我们能够清楚的知道MySQL是怎么执行我们的SQL语句的，执行某个查询语句总共查询了多少条记录，使用了什么表以及多表的链接顺序是怎么样的，该查询使用了哪些索引等等信息，有了这些信息，我们能够根据多次执行和分析优化我们的数据库，该建立索引的建索引，该删除的索引就删除掉。 FOR UPDATE难度指数：★ ★ ☆ ☆ ☆推荐指数：★ ★ ★ ★ ★有时我们有这样的一种情况，就是需要将某个SELECT语句查询的行进行锁定，防止其他客户端修改，那么这个时候，我们可以使用这个指示符来完成。 DELAYED难度指数：★ ★ ☆ ☆ ☆推荐指数：★ ★ ★ ★ ★有时发现我们的产品的某个插入、更新操作不需要立即生效，也就是一些对读要求高、写要求不太高的应用，可以使用这个指示符，就是将这个插入或者修改后的数据不是立即写入到磁盘文件中去，而是等到MySQL数据库非常空闲的时候再进行写入的操作，从这里来看，这个指示符也算是一个小的优化性指示符。 SQL_CACHE难度指数：★ ★ ☆ ☆ ☆推荐指数：★ ★ ★ ★ ★有时我们的产品读操作非常多，修改频率比较低，那么这个时候我们能够在执行select查询的时候指定sql_cache这个指示符，这样该查询语句和相应的查询结果将被缓存起来，那么下次执行同样的查询语句时，如果数据没有发生改变，那么将直接返回这个缓存的结果给客户端，从这里来看，这个查询语句指示符主要用于一些特性应用场景的优化操作。 ON DUPLICATE KEY UPDATE难度指数：★ ★ ☆ ☆ ☆推荐指数：★ ★ ★ ★ ★我们知道，在MySQL中有一个特殊的语句就是Replace语句，就是当插入的时候，我们发现某个条件（这里需要注意的是，这里指的是唯一索引或主键）的数据已经存在了，那么这个时候就先删除这条数据，然后再插入新的数据，也就是先删除再插入，但是有时候我们仅仅需要的是，如果存在了仅仅修改某个字段的值，而不是删除再插入，那么这个时候可以使用ON DUPLICATE KEY UPDATE来完成。]]></content>
      <categories>
        <category>Essay</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[从地址栏输入URL到页面加载完成发生了什么？]]></title>
    <url>%2F2017%2F04%2F08%2F%E4%BB%8E%E5%9C%B0%E5%9D%80%E6%A0%8F%E8%BE%93%E5%85%A5URL%E5%88%B0%E9%A1%B5%E9%9D%A2%E5%8A%A0%E8%BD%BD%E5%AE%8C%E6%88%90%E5%8F%91%E7%94%9F%E4%BA%86%E4%BB%80%E4%B9%88%EF%BC%9F%2F</url>
    <content type="text"><![CDATA[不管是前端还是后台开发，在找工作的时候，只要涉及到网络方面的知识，必然会问到这样一个问题：当我在浏览器的地址栏里输入一个完整的URL，在按下回车直至页面加载完成，整个过程发生了什么？这是一道考察综合能力的面试题，今天我们就一起来总结下该如何回答这个问题，当然我只是在这里讲解主要的知识点，涉及到的细节还需要大家再去找资料看。整体过程在这整个过程中，大致可以分为以下几个过程 DNS域名解析 TCP连接 HTTP请求 处理请求返回HTTP响应 页面渲染 关闭连接 DNS域名解析 首先我们应该要知道的是，在地址栏输入的域名并不是最后资源所在的真实位置，域名只是与IP地址的一个映射。网络服务器的IP地址那么多，我们不可能去记一串串的数字，因此域名就产生了，域名解析的过程实际是将域名还原为IP地址的过程。DNS域名解析有两种方法，分别是迭代查询和递归查询 迭代查询 递归查询 TCP连接在通过第一步的DNS域名解析后，获取到了服务器的IP地址，在获取到IP地址后，便会开始建立一次连接，这是由TCP协议完成的，主要通过三次握手进行连接。 三次握手HTTP请求在确认与服务器建立连接后，便会发送一个HTTP请求，HTTP请求的报文主要包括请求行，请求头，请求正文。请求行的内容一般类似于：GET index.html HTTP/1.1请求头的内容一般如下，可以通过浏览器开发者工具查看 请求头请求体一般包含请求传递的参数 请求体处理HTTP请求并响应服务器在收到浏览器发送的HTTP请求之后，会将收到的HTTP报文封装成HTTP的Request对象，并通过不同的Web服务器进行处理，处理完的结果以HTTP的Response对象返回，主要包括状态码，响应头，响应报文三个部分。状态码主要包括以下部分1xx：指示信息–表示请求已接收，继续处理。2xx：成功–表示请求已被成功接收、理解、接受。3xx：重定向–要完成请求必须进行更进一步的操作。4xx：客户端错误–请求有语法错误或请求无法实现。5xx：服务器端错误–服务器未能实现合法的请求。响应头主要由Cache-Control、 Connection、Date、Pragma等组成响应体为服务器返回给浏览器的信息，主要由HTML，css，js，图片文件组成页面渲染页面DOM树的渲染是个复杂的过程，需要深入了解DOM原理，这里简要描述一下，主要过程如下 DOM树渲染关闭连接在页面元素传输完成后，会选择关闭连接，此时用到的是TCP四次挥手。 TCP四次挥手总结至此一个完成的URL从输入到加载的过程就分析完了。]]></content>
      <categories>
        <category>Essay</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[ElasticSearch + Canal 开发千万级的实时搜索系统]]></title>
    <url>%2F2017%2F04%2F08%2FElasticSearch-Canal-%E5%BC%80%E5%8F%91%E5%8D%83%E4%B8%87%E7%BA%A7%E7%9A%84%E5%AE%9E%E6%97%B6%E6%90%9C%E7%B4%A2%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[公司是做社交相关产品的，社交类产品对搜索功能需求要求就比较高，需要根据用户城市、用户ID昵称等进行搜索。项目原先的搜索接口采用SQL查询的方式实现，数据库表采用了按城市分表的方式。但随着业务的发展，搜索接口调用频次越来越高，搜索接口压力越来越大，搜索数据库经常崩溃，从而导致搜索功能经常不能使用。ElasticSearch + Canal 开发千万级的实时搜索系统从上面的系统架构图可以看出，当用户修改资料时，接口会修改用户库信息，接着触发器会将改变的用户信息写入临时表。定时脚本每隔1分钟扫描一次临时表，将变更的数据写入到搜索库中。当用户再次请求搜索接口时，就可以搜索到最新的数据。从技术层面分析，原搜索系统的设计有以下缺点：搜索信息不实时。当用户修改信息时，需要等待1分钟的时间才能将最新的用户信息同步到搜索数据库中。ID、昵称搜索速度慢。按照地区分表的数据库设计是为了减轻数据库压力，保证大部分按照地区搜索的请求能正常响应。但是如果用户按照ID或昵称搜索，那么我们就需要对成千上万个地区表全都搜索一次，这时间复杂度可想而知。很多时候按照昵称和ID搜索速度太慢，需要10多秒才能响应。系统稳定性、拓展性以及处理能力差。这可以归结为技术老旧，无法满足业务需求。随着搜索量的提升，对数据库的压力将会越来越大，而MySQL数据库天然不适合用来应对海量的请求。现在已经有更加成熟的ElasticSearch可以用来做搜索方面的业务。触发器不便于管理。触发器这种东西不好维护，并且扩展性很差，一旦修改的请求变多，很可能导致整个数据库崩溃（用户库崩溃是很严重的）。我们总结一下新搜索系统需要解决的几个问题：海量请求。几百万的请求毫无压力，上千万上亿也要可以扛得住。实时搜索。指的是当一个用户修改了其数据之后，另一个用户能实时地搜索到改用户。海量请求。要扛得起海量的搜索请求，可以使用ElasticSearch来实现，它是在Lucene的基础上进行封装的一个开源项目，它将Lucene复杂的原理以及API封装起来，对外提供了一个易用的API接口。ElasticSearch现在已经广泛地被许多公司使用，其中包括：爱奇艺、百姓网、58到家等公司。实时搜索。阿里有一个开源项目Canal，就是用来解决这个问题的，Canal项目利用了MySQL数据库主从同步的原理，将Canal Server模拟成一台需要同步的从库，从而让主库将binlog日志流发送到Canal Server接口。Canal项目对binlog日志的解析进行了封装，我们可以直接得到解析后的数据，而不需要理会binlog的日志格式。而且Canal项目整合了zookeeper，整体实现了高可用，可伸缩性强，是一个不错的解决方案。经过一段时间的技术预研，我们设计了整个搜索技术架构：ElasticSearch + Canal 开发千万级的实时搜索系统从架构图可以看出整个系统分为两大部分：Canal数据变更服务平台。这部分负责解析MySQL的binlog日志，并将其解析后的数据封装成特定的对象放到Kafka中。Kafka数据消费方。这部分负责消费存放在Kafka中的消息，当消费方拿到具体的用户表变更消息时，将最新的用户信息存放到ES数据仓库中。Canal技术变更基础平台因为考虑到未来可能有其他项目需要监控数据库某些表的变化，因此我们将Canal获取MySQL数据变更部分做成一个公用的平台。当有其他业务需要增加监控的表时，我们可以直接修改配置文件，重启服务器即可完成添加，极大地提高了开发效率。在这一部分中，主要分为两大部分：Canal Server 和 Canal Client。Canal Server端。Canal Server伪装成MySQL的一个从库，使主库发送binlog日志给 Canal Server，Canal Server 收到binlog消息之后进行解析，解析完成后将消息直接发送给Canal Client。在Canal Server端可以设置配置文件进行具体scheme（数据库）和table（数据库表）的筛选，从而实现动态地增加对数据库表的监视。Canal Client端。Canal Client端接收到Canal Server的消息后直接将消息存到Kafka指定Partition中，并将最新的binlogid发送给zookeeper集群保存。Kafka消息消费端Canal技术变更平台在获取到对应的数据库变更消息后会将其放到指定的Kafka分片里，具体的业务项目需要到指定的Kafka片区里消费对应的数据变更消息，之后根据具体的业务需求进行处理。因为Canal变化是根据表为最小单位进行地，因此我在实现方面定义了一个以表为处理单位的MsgDealer接口：public interface MsgDealer { void deal(CanalMsgVo canalMsgVo); }搜索库涉及对5个表的监视，因此我实现了5个对应的处理类：ElasticSearch + Canal 开发千万级的实时搜索系统针对不同表的数据变化，自动调用不同的实现类进行处理。]]></content>
      <categories>
        <category>Essay</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[IDEA中非常用的几款插件，分享]]></title>
    <url>%2F2017%2F04%2F08%2FIDEA%E4%B8%AD%E9%9D%9E%E5%B8%B8%E7%94%A8%E7%9A%84%E5%87%A0%E6%AC%BE%E6%8F%92%E4%BB%B6%EF%BC%8C%E5%88%86%E4%BA%AB%2F</url>
    <content type="text"><![CDATA[插件名称 插件介绍 官网地址 GitOSC 开源中国的码云插件 https://plugins.jetbrains.com/plugin/8383-gitosc IDE Features Trainer IntelliJ IDEA 官方出的学习辅助插件 https://plugins.jetbrains.com/plugin/8554?pr=idea Key promoter 快捷键提示 https://plugins.jetbrains.com/plugin/4455?pr=idea Grep Console 自定义设置控制台输出颜色 https://plugins.jetbrains.com/idea/plugin/7125-grep-console String Manipulation 驼峰式命名和下划线命名交替变化 https://plugins.jetbrains.com/plugin/2162?pr=idea CheckStyle-IDEA 代码规范检查 https://plugins.jetbrains.com/plugin/1065?pr=idea FindBugs-IDEA 潜在 Bug 检查 https://plugins.jetbrains.com/plugin/3847?pr=idea MetricsReloaded 代码复杂度检查 https://plugins.jetbrains.com/plugin/93?pr=idea Statistic 代码统计 https://plugins.jetbrains.com/plugin/4509?pr=idea JRebel Plugin 热部署 https://plugins.jetbrains.com/plugin/?id=4441 CodeGlance 在编辑代码最右侧，显示一块代码小地图 https://plugins.jetbrains.com/plugin/7275?pr=idea GsonFormat 把 JSON 字符串直接实例化成类 https://plugins.jetbrains.com/plugin/7654?pr=idea MultiMarkdown 书写 Markdown 文章 https://plugins.jetbrains.com/plugin/7896?pr=idea Eclipse Code Formatter 使用 Eclipse 的代码格式化风格，在一个团队中如果公司有规定格式化风格，这个可以使用。 https://plugins.jetbrains.com/plugin/6546?pr=idea Jindent-Source Code Formatter 自定义类、方法、doc、变量注释模板 http://plugins.jetbrains.com/plugin/2170?pr=idea ECTranslation 翻译插件 https://github.com/Skykai521/ECTranslation/releases Maven Helper Maven 辅助插件 https://plugins.jetbrains.com/plugin/7179-maven-helper]]></content>
      <categories>
        <category>Collection</category>
      </categories>
      <tags>
        <tag>IDE</tag>
        <tag>JetBrains</tag>
        <tag>IntelliJ IDEA</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[EL表达式fn:endsWith函数的bug]]></title>
    <url>%2F2017%2F03%2F24%2FEL%E8%A1%A8%E8%BE%BE%E5%BC%8Ffn-endsWith%E5%87%BD%E6%95%B0%E7%9A%84bug%2F</url>
    <content type="text"><![CDATA[jstl-1.2.jar 123456789101112public static boolean endsWith(String input, String substring) &#123; if (input == null) input = ""; if (substring == null) substring = ""; int index = input.indexOf(substring); // should be indexOf应该是lastIndexOf 才对 if (index == -1) return false; if ((index == 0) &amp;&amp; (substring.length() == 0)) return true; return index == input.length() - substring.length();&#125;]]></content>
      <categories>
        <category>Collection</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Jstl</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Sequences in MySQL]]></title>
    <url>%2F2017%2F03%2F24%2FSequences-in-MySQL%2F</url>
    <content type="text"><![CDATA[Sequences in MySQLJanuary 26, 2006 by ronald One piece of SQL functionality that doesn’t appear to have any consistency or an ANSI SQL Standard is the management of system generated sequential numbers, used for example in suggorate keys. MySQL uses AUTO_INCREMENT which serves the purposes adequately, however in my documenting of differences with Oracle in my upcoming MySQL Conference presentation “MySQL for Oracle Developers” there a number of key differences with Oracle’s SEQUENCE usage. MySQL AUTO_INCREMENT to Oracle SEQUENCE Differences AUTO_INCREMENT is limited to one column per tableAUTO_INCREMENT must be assigned to a specific table.column (not allowing multi table use)AUTO_INCREMENT is INSERTed as a not specified column, or a value of NULLThe MaxDB Reserved Words list includes SEQUENCE for the CREATE SEQUENCE however I’ve never used MaxDB. Other popular open source products such as PostgreSQL and Ingres use sequences. Refer to the references section for more details. Usage The following provides an example sytax usage within MySQL and Oracle. MySQL CREATE TABLE Movie(id INT NOT NULL AUTO_INCREMENT,name VARCHAR(60) NOT NULL,released YEAR NOT NULL,PRIMARY KEY (id)) ENGINE=InnoDB; INSERT INTO Movie (name,released) VALUES (‘Gladiator’,2000);INSERT INTO Movie (id,name,released) VALUES (NULL,’The Bourne Identity’,1998); Oracle CREATE TABLE Movie(id INT NOT NULL,name VARCHAR2(60) NOT NULL,released INT NOT NULL,PRIMARY KEY (id));CREATE SEQUENCE MovieSeq; INSERT INTO Movie (id,name,released) VALUES (MovieSeq.NEXTVAL,’Gladiator’,2000); You can within Oracle use a Before Insert trigger to simulate handling of the MySQL Insert syntax. Note: Within Oracle you will require a SEQUENCE per table and a TRIGGER per table. Oracle supports multiple triggers of the same type per table (not sure if MySQL supports this). CREATE OR REPLACE TRIGGER BRI_MOVIE_TRGBEFORE INSERT ON MovieFOR EACH ROWBEGIN SELECT MovieSeq.NEXTVAL INTO :new.id FROM DUAL;END BRI_MOVIE_TRG;.RUN; INSERT INTO Movie (name,released) VALUES (‘The Lion King’,1994); Oracle’s syntax uses the sequence name with .NEXTVAL or .CURVAL. Future Directions I would like to see a SEQUENCE implementation with MySQL (whether official or unofficial). I’m sure some enterprising person in the community already has one. Database abstraction layer systems would also most likely have implementations. I liked the PostgreSQL Syntax for ease of use with the following commands. NEXTVAL(‘sequence’);CURRVAL(‘sequence’);SETVAL(‘sequence’,value);Wanting something and doing something about it are two different things, so here is what I wiped together to demonstrate a possible implementation. It needs a lot more work in appropiate error handling. transaction management, testing and performance analysis, however it shows the options of one possible implementation. currval DROP TABLE IF EXISTS sequence;CREATE TABLE sequence (name VARCHAR(50) NOT NULL,current_value INT NOT NULL,increment INT NOT NULL DEFAULT 1,PRIMARY KEY (name)) ENGINE=InnoDB;INSERT INTO sequence VALUES (‘MovieSeq’,3,5);DROP FUNCTION IF EXISTS currval;DELIMITER $CREATE FUNCTION currval (seq_name VARCHAR(50))RETURNS INTEGERCONTAINS SQLBEGIN DECLARE value INTEGER; SET value = 0; SELECT current_value INTO value FROM sequence WHERE name = seq_name; RETURN value;END$DELIMITER ; Some Testing: mysql&gt; SELECT currval(‘MovieSeq’);+———————+| currval(‘MovieSeq’) |+———————+| 3 |+———————+1 row in set (0.00 sec)mysql&gt; SELECT currval(‘x’);+————–+| currval(‘x’) |+————–+| 0 |+————–+1 row in set, 1 warning (0.00 sec)mysql&gt; show warnings;+———+——+——————+| Level | Code | Message |+———+——+——————+| Warning | 1329 | No data to FETCH |+———+——+——————+1 row in set (0.00 sec) What was interesting was I originally used a cursor, as below, but the results for passing an invalid argument (basic boundary testing), returned a SQL error while the above implementation returned a more manageable warning. DECLARE c CURSOR FOR SELECT current_value FROM sequence WHERE name = seq_name; OPEN c; FETCH c INTO value; mysql&gt; select currval(‘x’);ERROR 1329 (02000): No data to FETCH Indeed the Apache Object Relational Bridge Sequence Manager section shows a very cool syntax for MSSQL. UPDATE TABLE SET @MAX_KEY = MAX_KEY = MAX_KEY + 1 UPDATE table SET var = column = value which effectively allows you to eliminated the need for a seperate UPDATE and SELECT for this type of operation. nextval DROP FUNCTION IF EXISTS nextval;DELIMITER $CREATE FUNCTION nextval (seq_name VARCHAR(50))RETURNS INTEGERCONTAINS SQLBEGIN UPDATE sequence SET current_value = current_value + increment WHERE name = seq_name; RETURN currval(seq_name);END$DELIMITER ; mysql&gt; select nextval(‘MovieSeq’);+———————+| nextval(‘MovieSeq’) |+———————+| 15 |+———————+1 row in set (0.09 sec) mysql&gt; select nextval(‘MovieSeq’);+———————+| nextval(‘MovieSeq’) |+———————+| 20 |+———————+1 row in set (0.01 sec) mysql&gt; select nextval(‘MovieSeq’);+———————+| nextval(‘MovieSeq’) |+———————+| 25 |+———————+1 row in set (0.00 sec) setval DROP FUNCTION IF EXISTS setval;DELIMITER $CREATE FUNCTION setval (seq_name VARCHAR(50), value INTEGER)RETURNS INTEGERCONTAINS SQLBEGIN UPDATE sequence SET current_value = value WHERE name = seq_name; RETURN currval(seq_name);END$DELIMITER ; mysql&gt; select setval(‘MovieSeq’,150);+————————+| setval(‘MovieSeq’,150) |+————————+| 150 |+————————+1 row in set (0.06 sec) mysql&gt; select curval(‘MovieSeq’);+———————+| currval(‘MovieSeq’) |+———————+| 150 |+———————+1 row in set (0.00 sec) mysql&gt; select nextval(‘MovieSeq’);+———————+| nextval(‘MovieSeq’) |+———————+| 155 |+———————+1 row in set (0.00 sec)]]></content>
      <categories>
        <category>Essay</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java动态代理与Cglib库]]></title>
    <url>%2F2017%2F03%2F22%2FJava%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86%E4%B8%8ECglib%E5%BA%93%2F</url>
    <content type="text"><![CDATA[JDK动态代理 代理模式是常用的Java设计模式，他的特征是代理类与委托类有同样的接口，代理类主要负责为委托类预处理消息、过滤消息、把消息转发给委托类，以及事后处理消息等。代理类与委托类之间通常会存在关联关系，一个代理类的对象与一个委托类的对象关联，代理类的对象本身并不真正实现服务，而是通过调用委托类的对象的相关方法，来提供特定的服务。 按照代理的创建时期，代理类可以分为两种。 静态代理：由程序员创建或特定工具自动生成源代码，再对其编译。在程序运行前，代理类的.class文件就已经存在了。 动态代理：在程序运行时，运用反射机制动态创建而成。 为什么使用动态代理？因为动态代理可以对请求进行任何处理。 哪些地方需要动态代理？不允许直接访问某些类；对访问要做特殊处理等。 目前Java开发包中包含了对动态代理的支持，但是其实现只支持对接口的的实现。 其实现主要通过java.lang.reflect.Proxy类和java.lang.reflect.InvocationHandler接口。 Proxy类主要用来获取动态代理对象，InvocationHandler接口用来约束调用者实现。 以下为模拟案例，通过动态代理实现在方法调用前后向控制台输出两句字符串。 定义一个HelloWorld接口：[java] view plain copypackage com.ljq.test; /** 定义一个HelloWorld接口 @author jiqinlin */public interface HelloWorld { public void sayHelloWorld();} 类HelloWorldImpl是HelloWorld接口的实现：[java] view plain copypackage com.ljq.test; /** 类HelloWorldImpl是HelloWorld接口的实现 @author jiqinlin */public class HelloWorldImpl implements HelloWorld{ public void sayHelloWorld() { System.out.println(&quot;HelloWorld!&quot;); } } HelloWorldHandler是 InvocationHandler接口实现：[java] view plain copypackage com.ljq.test; import java.lang.reflect.InvocationHandler; import java.lang.reflect.Method; /** 实现在方法调用前后向控制台输出两句字符串 @author jiqinlin */public class HelloWorldHandler implements InvocationHandler{ //要代理的原始对象 private Object obj; public HelloWorldHandler(Object obj) { super(); this.obj = obj; } /** 在代理实例上处理方法调用并返回结果 @param proxy 代理类 @param method 被代理的方法 @param args 该方法的参数数组*/public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { Object result = null; //调用之前 doBefore(); //调用原始对象的方法 result=method.invoke(obj, args); //调用之后 doAfter(); return result;} private void doBefore(){ System.out.println(“before method invoke”);} private void doAfter(){ System.out.println(“after method invoke”);} } 测试类：[java] view plain copypackage com.ljq.test; import java.lang.reflect.InvocationHandler;import java.lang.reflect.Proxy; public class HelloWorldTest { public static void main(String[] args) { HelloWorld helloWorld=new HelloWorldImpl(); InvocationHandler handler=new HelloWorldHandler(helloWorld); //创建动态代理对象 HelloWorld proxy=(HelloWorld)Proxy.newProxyInstance( helloWorld.getClass().getClassLoader(), helloWorld.getClass().getInterfaces(), handler); proxy.sayHelloWorld(); } } 运行结果为：[plain] view plain copybefore method invokeHelloWorld!after method invoke 基本流程：用Proxy类创建目标类的动态代理，创建时需要指定一个自己实现InvocationHandler接口的回调类的对象，这个回调类中有一个invoke()用于拦截对目标类各个方法的调用。创建好代理后就可以直接在代理上调用目标对象的各个方法。 JDK自从1.3版本开始，就引入了动态代理，并且经常被用来动态地创建代理。JDK的动态代理用起来非常简单，但它有一个限制，就是使用动态代理的对象必须实现一个或多个接口。比如上面的HelloWorldImpl类，实现了HelloWorld接口，所以可以用JDK的动态代理。如果想代理没有实现接口的继承的类，该怎么办？ CGLIB就是最好的选择（https://github.com/cglib/cglib，使用apache license 2.0）。其他比较有名的还有从JBoss项目衍生出来的Javassist（https://github.com/jboss-javassist/javassist），这里介绍Cglib。 Cglib代码生成库 CGlib是一个强大的，高性能，高质量的Code生成类库。它可以在运行期扩展Java类与实现Java接口。其底层是通过小而快的字节码处理框架ASM（http://forge.ow2.org/projects/asm，使用BSD License）来转换字节码并生成新的类。大部分功能实际上是asm所提供的，CGlib只是封装了asm，简化了asm的操作，实现了在运行期动态生成新的class。 CGlib被许多AOP的框架使用，例如spring AOP和dynaop，为他们提供方法的interception（拦截）；最流行的OR Mapping工具hibernate也使用CGLIB来代理单端single-ended（多对一和一对一）关联（对集合的延迟抓取，是采用其他机制实现的）；EasyMock和jMock是通过使用模仿（moke）对象来测试java代码的包，它们都通过使用CGLIB来为那些没有接口的类创建模仿（moke）对象。 CGLIB包的基本代码很少，但学起来有一定的困难，主要是缺少文档，API描述过于简单，这也是开源软件的一个不足之处。目前CGLIB的版本是cglib-2.2.jar，主要由一下部分组成： （1）net.sf.cglib.core：底层字节码处理类，他们大部分与ASM有关系。 （2）net.sf.cglib.transform：编译期或运行期类和类文件的转换。 （3）net.sf.cglib.proxy ：实现创建代理和方法拦截器的类。 （4）net.sf.cglib.reflect ：实现快速反射和C#风格代理的类。 （5）net.sf.cglib.util：集合排序工具类。 （6）net.sf.cglib.beans：JavaBean相关的工具类。 CGLIB包是在ASM之上的一个高级别的层。对代理那些没有实现接口的类非常有用。本质上，它是通过动态的生成一个子类去覆盖所要代理类的不是final的方法，并设置好callback，则原有类的每个方法调用就会转变成调用用户定义的拦截方法（interceptors），这比JDK动态代理方法快多了。可见，Cglib的原理是对指定的目标类动态生成一个子类，并覆盖其中方法实现增强，但因为采用的是继承，所以不能对final修饰的类和final方法进行代理。 用Cglib创建动态代理 下图表示Cglib常用到的几类。 图1 Cglib主要的接口 创建一个具体类的代理时，通常要用到的CGLIB包的APIs： net.sf.cglib.proxy.Callback接口：在CGLIB包中是一个很关键的接口，所有被net.sf.cglib.proxy.Enhancer类调用的回调（callback）接口都要继承这个接口。 net.sf.cglib.proxy.MethodInterceptor接口：是最通用的回调（callback）类型，它经常被AOP用来实现拦截（intercept）方法的调用。这个接口只定义了一个方法。[java] view plain copypublic Object intercept(Object object, java.lang.reflect.Method method, Object[] args, MethodProxy proxy) throws Throwable; 当net.sf.cglib.proxy.MethodInterceptor做为所有代理方法的回调 （callback）时，当对基于代理的方法调用时，在调用原对象的方法的之前会调用这个方法，如图下图所示。第一个参数是代理对像，第二和第三个参数分别 是拦截的方法和方法的参数。原来的方法可能通过使用java.lang.reflect.Method对象的一般反射调用，或者使用 net.sf.cglib.proxy.MethodProxy对象调用。net.sf.cglib.proxy.MethodProxy通常被首选使用，因为它更快。在这个方法中，我们可以在调用原方法之前或之后注入自己的代码。 图1 net.sf.cglib.proxy.MethodInterceptor能够满足任何的拦截（interception ）需要，当对有些情况下可能过度。为了简化和提高性能，CGLIB包提供了一些专门的回调（callback）类型。例如： net.sf.cglib.proxy.FixedValue：为提高性能，FixedValue回调对强制某一特别方法返回固定值是有用的。 net.sf.cglib.proxy.NoOp：NoOp回调把对方法调用直接委派到这个方法在父类中的实现。 net.sf.cglib.proxy.LazyLoader：当实际的对象需要延迟装载时，可以使用LazyLoader回调。一旦实际对象被装载，它将被每一个调用代理对象的方法使用。 net.sf.cglib.proxy.Dispatcher：Dispathcer回调和LazyLoader回调有相同的特点，不同的是，当代理方法被调用时，装载对象的方法也总要被调用。 net.sf.cglib.proxy.ProxyRefDispatcher：ProxyRefDispatcher回调和Dispatcher一样，不同的是，它可以把代理对象作为装载对象方法的一个参数传递。 代理类的所以方法经常会用到回调（callback），当然你也可以使用net.sf.cglib.proxy.CallbackFilter 有选择的对一些方法使用回调（callback），这种考虑周详的控制特性在JDK的动态代理中是没有的。在JDK代理中，对 java.lang.reflect.InvocationHandler方法的调用对代理类的所有方法都有效。 CGLIB的代理包也对net.sf.cglib.proxy.Mixin提供支持。基本上，它允许多个对象被绑定到一个单一的大对象。在代理中对方法的调用委托到下面相应的对象中。 接下来我们看看如何使 用CGLIB代理APIs创建代理。 1、创建一个简单的代理 CGLIB代理最核心类net.sf.cglib.proxy.Enhancer， 为了创建一个代理，最起码你要用到这个类。首先，让我们使用NoOp回调创建一个代理。[java] view plain copy/** Create a proxy using NoOp callback. The target class must have a default zero-argument constructor @param targetClass the super class of the proxy @return a new proxy for a target class instance*/public Object createProxy(Class targetClass) { Enhancer enhancer = new Enhancer(); enhancer.setSuperclass(targetClass); enhancer.setCallback(NoOp.INSTANCE); return enhancer.create();} 返回值是target类一个实例的代理。在这个例子中，我们为net.sf.cglib.proxy.Enhancer 配置了一个单一的回调（callback）。我们可以看到很少直接创建一个简单的代理，而是创建一个net.sf.cglib.proxy.Enhancer的实例，在net.sf.cglib.proxy.Enhancer类中你可使用静态帮助方法创建一个简单的代理。一般推荐使用上面例子的方法创建代理，因为它允许你通过配置net.sf.cglib.proxy.Enhancer实例很好的控制代理的创建。 要注意的是，target类是作为产生的代理的父类传进来的。不同于JDK的动态代理，它不能在创建代理时传target对象，target对象必须被CGLIB包来创建。在这个例子中，默认的无参数构造器时用来创建target实例的。如果你想用CGLIB来创建有参数的实例，用net.sf.cglib.proxy.Enhancer.create(Class[], Object[])方法替代net.sf.cglib.proxy.Enhancer.create()就可以了。方法中第一个参数定义了参数的类型，第 二个是参数的值。在参数中，基本类型应被转化成类的类型。 2、使用MethodInterceptor创建一个代理 为了更好的使用代理，我们可以使用自己定义的MethodInterceptor类型回调（callback）来代替net.sf.cglib.proxy.NoOp回调。当对代理中所有方法的调用时，都会转向MethodInterceptor类型的拦截（intercept）方法，在拦截方法中再调用底层对象相应的方法。下面我们举个例子，假设你想对目标对象的所有方法调用进行权限的检查，如果没有经过授权，就抛出一个运行时的异常AuthorizationException。其中AuthorizationService.java接口的代码如下：[java] view plain copypackage com.lizjason.cglibproxy; import java.lang.reflect.Method; /** A simple authorization service for illustration purpose. @author Jason Zhicheng Li (jason@lizjason.com)*/public interface AuthorizationService { void authorize(Method method);} 对net.sf.cglib.proxy.MethodInterceptor接口的实现的类AuthorizationInterceptor.java代码如下：[java] view plain copypackage com.lizjason.cglibproxy.impl;import java.lang.reflect.Method;import net.sf.cglib.proxy.MethodInterceptor;import net.sf.cglib.proxy.MethodProxy; import com.lizjason.cglibproxy.AuthorizationService; /** A simple MethodInterceptor implementation to apply authorization checks for proxy method calls.*/public class AuthorizationInterceptor implements MethodInterceptor { private AuthorizationService authorizationService; /** Create a AuthorizationInterceptor with the given AuthorizationService*/public AuthorizationInterceptor (AuthorizationService authorizationService) { this.authorizationService = authorizationService;} /** Intercept the proxy method invocations to inject authorization check. * The original method is invoked through MethodProxy.*/public Object intercept(Object object, Method method, Object[] args, MethodProxy methodProxy) throws Throwable { if (authorizationService != null) { //may throw an AuthorizationException if authorization failed authorizationService.authorize(method); } return methodProxy.invokeSuper(object, args);}} 我们可以看到在拦截方法中，首先进行权限的检查，如果通过权限的检查，拦截方法再调用目标对象的原始方法。由于性能的原因，对原始方法的调用我们使用CGLIB的net.sf.cglib.proxy.MethodProxy对象，而不是反射中一般使用java.lang.reflect.Method对象。 下面是一个完整的使用MethodInterceptor的例子。[java] view plain copypackage cglibexample; import java.lang.reflect.Method;import net.sf.cglib.proxy.Enhancer;import net.sf.cglib.proxy.MethodInterceptor;import net.sf.cglib.proxy.MethodProxy; /** 定义一个HelloWorld类，没有实现接口 */class HelloWorld { public void sayHelloWorld() { System.out.println(&quot;HelloWorld!&quot;); }} /** 通过Cglib实现在方法调用前后向控制台输出两句字符串 */class CglibProxy implements MethodInterceptor { //要代理的原始对象 private Object obj; public Object createProxy(Object target) { this.obj = target; Enhancer enhancer = new Enhancer(); // 设置要代理的目标类，以扩展它的功能 enhancer.setSuperclass(this.obj.getClass()); // 设置单一回调对象，在回调中拦截对目标方法的调用 enhancer.setCallback(this); //设置类装载器 enhancer.setClassLoader(target.getClass().getClassLoader()); //创建代理对象 return enhancer.create(); } /** 回调方法:在代理实例上拦截并处理目标方法的调用，返回结果 @param proxy 代理类 @param method 被代理的方法 @param params 该方法的参数数组 @param methodProxy*/@Overridepublic Object intercept(Object proxy, Method method, Object[] params, MethodProxy methodProxy) throws Throwable { Object result = null; // 调用之前 doBefore(); // 调用目标方法，用methodProxy, // 而不是原始的method，以提高性能 result = methodProxy.invokeSuper(proxy, params); // 调用之后 doAfter(); return result;} private void doBefore() { System.out.println(“before method invoke”);} private void doAfter() { System.out.println(“after method invoke”);}} public class TestCglib { public static void main(String[] args) { CglibProxy cglibProxy = new CglibProxy(); HelloWorld hw = (HelloWorld) cglibProxy.createProxy(new HelloWorld()); hw.sayHelloWorld(); } } 输出结果：[plain] view plain copybefore method invokeHelloWorld!after method invoke 基本流程：需要自己写代理类，它实现MethodInterceptor接口，有一个intercept()回调方法用于拦截对目标方法的调用，里面使用methodProxy来调用目标方法。创建代理对象要用Enhance类，用它设置好代理的目标类、有intercept()回调的代理类实例、最后用create()创建并返回代理实例。 3、使用CallbackFilter在方法层设置回调 net.sf.cglib.proxy.CallbackFilter允许我们在方法层设置回调（callback）。假如你有一个PersistenceServiceImpl类，它有两个方法：save和load，其中方法save需要权限检查，而方法load不需要权限检查。[java] view plain copyimport com.lizjason.cglibproxy.PersistenceService;import java.lang.reflect.Method;import net.sf.cglib.proxy.CallbackFilter; /** A simple implementation of PersistenceService interface*/class PersistenceServiceImpl implements PersistenceService { //需要权限检查 public void save(long id, String data) { System.out.println(data + &quot; has been saved successfully.&quot;); } //不需要权限检查 public String load(long id) { return &quot;Test CGLIB CallBackFilter&quot;; }} /** An implementation of CallbackFilter for PersistenceServiceImpl*/public class PersistenceServiceCallbackFilter implements CallbackFilter { //callback index for save method private static final int SAVE = 0; //callback index for load method private static final int LOAD = 1; /** Specify which callback to use for the method being invoked. @param method the method being invoked. @return*/@Overridepublic int accept(Method method) { //指定各方法的代理回调索引 String name = method.getName(); if (“save”.equals(name)) { return SAVE; } // for other methods, including the load method, use the // second callback return LOAD;}} accept方法中对代理方法和回调进行了匹配，返回的值是某方法在回调数组中的索引。下面是PersistenceServiceImpl类代理的实现。[java] view plain copy…Enhancer enhancer = new Enhancer();enhancer.setSuperclass(PersistenceServiceImpl.class);//设置回调过滤器CallbackFilter callbackFilter = new PersistenceServiceCallbackFilter();enhancer.setCallbackFilter(callbackFilter);//创建各个目标方法的代理回调AuthorizationService authorizationService = …Callback saveCallback = new AuthorizationInterceptor(authorizationService);Callback loadCallback = NoOp.INSTANCE;//顺序要与指定的回调索引一致Callback[] callbacks = new Callback[]{saveCallback, loadCallback };enhancer.setCallbacks(callbacks); //设置回调…return (PersistenceServiceImpl)enhancer.create(); //创建代理对象 在这个例子中save方法使用了AuthorizationInterceptor实例，load方法使用了NoOp实例。此外，你也可以通过net.sf.cglib.proxy.Enhancer.setInterfaces(Class[])方法指定代理对象所实现的接口。 除了为net.sf.cglib.proxy.Enhancer指定回调数组，你还可以通过net.sf.cglib.proxy.Enhancer.setCallbackTypes(Class[]) 方法指定回调类型数组。当创建代理时，如果你没有回调实例的数组，就可以使用回调类型。象使用回调一样，你必须使用net.sf.cglib.proxy.CallbackFilter为每一个方法指定一个回调类型索引。 4、使用Mixin Mixin通过代理方式将多种类型的对象绑定到一个大对象上，这样对各个目标类型中的方法调用可以直接在这个大对象上进行。下面是一个例子。 [java] view plain copyimport net.sf.cglib.proxy.Mixin; interface MyInterfaceA { public void methodA(); } interface MyInterfaceB { public void methodB(); } class MyInterfaceAImpl implements MyInterfaceA { @Override public void methodA() { System.out.println(&quot;MyInterfaceAImpl.methodA()&quot;); } } class MyInterfaceBImpl implements MyInterfaceB { @Override public void methodB() { System.out.println(&quot;MyInterfaceBImpl.methodB()&quot;); } } public class Main { public static void main(String[] args) { //各个对象对应的类型 Class[] interfaces = new Class[]{MyInterfaceA.class, MyInterfaceB.class}; //各个对象 Object[] delegates = new Object[]{new MyInterfaceAImpl(), new MyInterfaceBImpl()}; //将多个对象绑定到一个大对象上 Object obj = Mixin.create(interfaces, delegates); //直接在大对象上调用各个目标方法 ((MyInterfaceA)obj).methodA(); ((MyInterfaceB)obj).methodB(); } } 动态生成Bean 我们知道，Java Bean包含一组属性字段，用这些属性来存储和获取值。通过指定一组属性名和属性值的类型，我们可以使用Cglib的BeanGenerator和BeanMap来动态生成Bean。下面是一个例子。[java] view plain copyimport java.lang.reflect.Method;import java.util.HashMap;import java.util.Iterator;import java.util.Map;import java.util.Set;import net.sf.cglib.beans.BeanGenerator;import net.sf.cglib.beans.BeanMap; /** 动态实体bean @author cuiran @version 1.0*/class CglibBean { //Bean实体Object public Object object = null; //属性map public BeanMap beanMap = null; public CglibBean() { super(); } @SuppressWarnings(“unchecked”) public CglibBean(Map propertyMap) { //用一组属性生成实体Bean this.object = generateBean(propertyMap); //用实体Bean创建BeanMap，以便可以设置和获取Bean属性的值 this.beanMap = BeanMap.create(this.object); } /** 给bean中的属性赋值 @param property 属性名 @param value 值*/public void setValue(String property, Object value) { beanMap.put(property, value);} /** 获取bean中属性的值 @param property 属性名 @return 值*/public Object getValue(String property) { return beanMap.get(property);} /** 得到该实体bean对象 @return*/public Object getObject() { return this.object;} @SuppressWarnings(“unchecked”)private Object generateBean(Map propertyMap) { //根据一组属性名和属性值的类型，动态创建Bean对象 BeanGenerator generator = new BeanGenerator(); Set keySet = propertyMap.keySet(); for (Iterator i = keySet.iterator(); i.hasNext();) { String key = (String) i.next(); generator.addProperty(key, (Class) propertyMap.get(key)); } return generator.create(); //创建Bean}} /** Cglib测试类 @author cuiran @version 1.0*/public class CglibTest { @SuppressWarnings(“unchecked”) public static void main(String[] args) throws ClassNotFoundException { // 设置类成员属性 HashMap&lt;String, Class&gt; propertyMap = new HashMap&lt;&gt;(); propertyMap.put(&quot;id&quot;, Class.forName(&quot;java.lang.Integer&quot;)); propertyMap.put(&quot;name&quot;, Class.forName(&quot;java.lang.String&quot;)); propertyMap.put(&quot;address&quot;, Class.forName(&quot;java.lang.String&quot;)); // 生成动态Bean CglibBean bean = new CglibBean(propertyMap); // 给Bean设置值 bean.setValue(&quot;id&quot;, 123); //Auto-boxing bean.setValue(&quot;name&quot;, &quot;454&quot;); bean.setValue(&quot;address&quot;, &quot;789&quot;); // 从Bean中获取值，当然获得值的类型是Object System.out.println(&quot; &gt;&gt; id = &quot; + bean.getValue(&quot;id&quot;)); System.out.println(&quot; &gt;&gt; name = &quot; + bean.getValue(&quot;name&quot;)); System.out.println(&quot; &gt;&gt; address = &quot; + bean.getValue(&quot;address&quot;)); // 获得bean的实体 Object object = bean.getObject(); // 通过反射查看所有方法名 Class clazz = object.getClass(); Method[] methods = clazz.getDeclaredMethods(); for (Method curMethod : methods) { System.out.println(curMethod.getName()); } }} 输出结果：[java] view plain copy id = 123name = 454address = 789getAddressgetNamegetIdsetNamesetIdsetAddress CGLIB轻松实现延迟加载 通过使用LazyLoader，可以实现延迟加载，即在没有访问对象的字段或方法之前并不加载对象，只有当要访问对象的字段或方法时才进行加载。下面是一个例子。[java] view plain copyimport net.sf.cglib.proxy.Enhancer;import net.sf.cglib.proxy.LazyLoader; class TestBean { private String userName; /** * @return the userName */ public String getUserName() { return userName; } /** * @param userName the userName to set */ public void setUserName(String userName) { this.userName = userName; } } //延迟加载代理类class LazyProxy implements LazyLoader { //拦截Bean的加载，本方法会延迟处理 @Override public Object loadObject() throws Exception { System.out.println(&quot;开始延迟加载!&quot;); TestBean bean = new TestBean(); //创建实体Bean bean.setUserName(&quot;test&quot;); //给一个属性赋值 return bean; //返回Bean } } public class BeanTest { public static void main(String[] args) { //创建Bean类型的延迟加载代理实例 TestBean bean = (TestBean) Enhancer.create(TestBean.class, new LazyProxy()); System.out.println(&quot;------&quot;); System.out.println(bean.getUserName()); } } 输出结果： [java] view plain copy开始延迟加载!test 我们创建TestBean类的延迟代理，通过LazyLoader中的loadObject()方法的拦截，实现对TestBean类的对象进行延迟加载。从输出可以看出，当创建延迟代理时，并没有立刻加载目标对象（因为还有输出“开始延迟加载!”），当通过代理访问目标对象的getUserName()方法时，就会加载目标对象。可见loadObject()是延迟执行的。]]></content>
      <categories>
        <category>Essay</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring 中使用 logback打印日志，替换其他日志如log4j,commons-logging]]></title>
    <url>%2F2017%2F03%2F21%2Fspring-%E4%B8%AD%E4%BD%BF%E7%94%A8-logback%E6%89%93%E5%8D%B0%E6%97%A5%E5%BF%97%EF%BC%8C%E6%9B%BF%E6%8D%A2%E5%85%B6%E4%BB%96%E6%97%A5%E5%BF%97%E5%A6%82log4j-commons-logging%2F</url>
    <content type="text"><![CDATA[Spring MVC集成slf4j-log4j关于slf4j和log4j的相关介绍和用法，网上有很多文章可供参考，但是关于logback的，尤其是spring MVC集成logback的，就相对少一些了，而且其中一些也有着这样那样的问题。进入正题之前先简单介绍下Spring MVC集成slf4j-log4j的过程，如下： 在pom.xml文件中添加slf4j-log4j的依赖，完成后的classpath中将新增三个jar包，分别是：slf4j-api.jar、log4j.jar及slf4j-log4j.jar 在当前classpath中添加log4j.properties配置文件，按照log4j的参数语法编写该文件 以上两步完成后，普通的Java项目就能使用slf4j-log4j进行日志处理了；对于Java Web项目，还需要在web.xml文件中配置Log4jConfigLocation和Log4jConfigListener log4j与logback简要比较本文意在阐述用logback替代log4j作为Spring MVC项目的日志处理组件。这两者虽然作者相同，但log4j早已被托管给Apache基金会维护，并且自从2012年5月之后就没有更新了。而logback从出生开始就是其作者奔着取代log4j的目的开发的，因此一方面logback继承了log4j大量的用法，使得学习和迁移的成本不高，另一方面logback在性能上要明显优于log4j，尤其是在大量并发的环境下，并且新增了一些log4j所没有的功能（如将日志文件压缩成zip包等） Spring MVC集成slf4j-logback添加依赖12345678910111213141516171819202122232425262728293031&lt;dependency&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;artifactId&gt;logback-classic&lt;/artifactId&gt; &lt;version&gt;1.1.4&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;artifactId&gt;logback-core&lt;/artifactId&gt; &lt;version&gt;1.1.4&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;log4j-over-slf4j&lt;/artifactId&gt; &lt;version&gt;1.7.20&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt; &lt;version&gt;1.7.21&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.logback-extensions&lt;/groupId&gt; &lt;artifactId&gt;logback-ext-spring&lt;/artifactId&gt; &lt;version&gt;0.1.2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;jcl-over-slf4j&lt;/artifactId&gt; &lt;version&gt;1.7.12&lt;/version&gt; &lt;/dependency&gt; 注意：删除原有的log4j.jar。如上所示是集成所需要的依赖，其中：第一个logback-classic包含了logback本身所需的slf4j-api.jar、logback-core.jar及logback-classsic.jar第二个logback-ext-spring是由官方提供的对Spring的支持，它的作用就相当于log4j中的Log4jConfigListener；这个listener，网上大多都是用的自己实现的，原因在于这个插件似乎并没有出现在官方文档的显要位置导致大多数人并不知道它的存在第三个jcl-over-slf4j是用来把Spring源代码中大量使用到的commons-logging替换成slf4j，只有在添加了这个依赖之后才能看到Spring框架本身打印的日志，否则只能看到开发者自己打印的日志 编写logback.xmllogback与log4j一样，也需要在classpath中编写配置文件。但logback配置文件似乎比log4j复杂一些：log4j不仅支持xml格式的配置文件，还支持properties格式的，而logback只支持xml格式的。好在官方提供了一个在线工具，可以将log4j的properties文件直接转换成logback的xml文件，地址如下：http://logback.qos.ch/translator/logback的详细用法及其xml文件的相关语法，可参见它的用户向导，地址如下：http://logback.qos.ch/manual/introduction.html 配置web.xml与log4j类似，logback集成到Spring MVC项目中，也需要在web.xml中进行配置，同样也是配置一个config location和一个config listener，如下所示：1234567&lt;context-param&gt; &lt;param-name&gt;logbackConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:logback.xml&lt;/param-value&gt; &lt;/context-param&gt; &lt;listener&gt; &lt;listener-class&gt;ch.qos.logback.ext.spring.web.LogbackConfigListener&lt;/listener-class&gt; &lt;/listener&gt; 其中LogbackConfigListener由前述的logback-ext-spring依赖提供，若不依赖它则找不到这个listener类 其它从上面可以看出，slf4j-log4j和slf4j-logback集成到Spring MVC（或推广到其它Java Web项目中）的步骤大体是相同的。集成完毕后，就可以通过slf4j提供的API隐藏掉logback（或log4j）的具体实现，直接进行日志处理了使用slf4j-api的时候，需要注意的是：slf4j采用了单例模式，项目中创建的每一个Logger实例都会按你传入的name（传入的Class&lt;?&gt;实例也会被转换成String型的name）保存到一个静态的ConcurrentHashMap中；因此只要name（或Class&lt;?&gt;实例）相同，每次返回的实际上都是同一个Logger实例。因此完全没必要把Logger实例作为常量或静态成员，随用随取即可。实际上，其作者也不建议那么做]]></content>
      <categories>
        <category>Essay</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Spring</tag>
      </tags>
  </entry>
</search>